# Azureè¯­éŸ³æœåŠ¡é›†æˆæŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜å¦‚ä½•åœ¨AIç”µè¯åº”ç­”ç³»ç»Ÿä¸­é›†æˆå’Œä½¿ç”¨Azureè¯­éŸ³æœåŠ¡ã€‚

## ğŸ“‹ åŠŸèƒ½æ¦‚è§ˆ

### âœ… å·²å®ç°çš„æ ¸å¿ƒåŠŸèƒ½

#### ğŸ¤ è¯­éŸ³è½¬æ–‡å­— (STT)
- **æµå¼å®æ—¶è¯†åˆ«**: æ”¯æŒè¿ç»­éŸ³é¢‘æµå¤„ç†ï¼Œå®ç°ä½å»¶è¿Ÿè¯­éŸ³è¯†åˆ«
- **å¤šè¯­è¨€æ”¯æŒ**: æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ç­‰å¤šç§è¯­è¨€çš„è¯­éŸ³è¯†åˆ«
- **é«˜ç²¾åº¦è¯†åˆ«**: æä¾›è¯çº§æ—¶é—´æˆ³å’Œç½®ä¿¡åº¦è¯„åˆ†
- **éŸ³é¢‘è´¨é‡æ£€æµ‹**: è‡ªåŠ¨è¯„ä¼°éŸ³é¢‘è´¨é‡å¹¶æä¾›è´¨é‡åé¦ˆ
- **å¹¶å‘ä¼šè¯ç®¡ç†**: æ”¯æŒå¤šä¸ªè¯†åˆ«ä¼šè¯åŒæ—¶è¿›è¡Œ

#### ğŸ”Š æ–‡å­—è½¬è¯­éŸ³ (TTS)
- **ç¥ç»è¯­éŸ³åˆæˆ**: é›†æˆAzure Neural Voiceï¼Œæä¾›è‡ªç„¶æµç•…çš„è¯­éŸ³
- **å¤šç§è¯­éŸ³é£æ ¼**: æ”¯æŒå‹å¥½ã€ä¸“ä¸šã€æ–°é—»æ’­æŠ¥ç­‰å¤šç§è¡¨è¾¾é£æ ¼
- **éŸµå¾‹ç²¾ç¡®æ§åˆ¶**: å¯è°ƒèŠ‚è¯­é€Ÿã€éŸ³è°ƒã€éŸ³é‡ç­‰è¯­éŸ³ç‰¹æ€§
- **æ™ºèƒ½ç¼“å­˜æœºåˆ¶**: é¢„è®¡ç®—å¸¸ç”¨å›å¤ï¼Œæ˜¾è‘—å‡å°‘åˆæˆå»¶è¿Ÿ
- **æµå¼éŸ³é¢‘è¾“å‡º**: æ”¯æŒè¾¹åˆæˆè¾¹æ’­æ”¾ï¼Œé™ä½é¦–å­—èŠ‚å»¶è¿Ÿ

#### âš™ï¸ é…ç½®ç®¡ç†
- **åŠ¨æ€é…ç½®åˆ‡æ¢**: æ”¯æŒè¿è¡Œæ—¶æ›´æ”¹è¯­éŸ³å‚æ•°å’Œä¼˜åŒ–è®¾ç½®
- **æ™ºèƒ½è¯­éŸ³æ¨è**: æ ¹æ®ç”¨æˆ·ç”»åƒè‡ªåŠ¨æ¨èæœ€é€‚åˆçš„è¯­éŸ³
- **æ€§èƒ½ä¼˜åŒ–æ¨¡å¼**: æä¾›å»¶è¿Ÿä¼˜åŒ–ã€è´¨é‡ä¼˜åŒ–ç­‰å¤šç§æ¨¡å¼
- **å¤šæ ¼å¼æ”¯æŒ**: æ”¯æŒWAVã€MP3ã€OPUSã€AACç­‰ä¸»æµéŸ³é¢‘æ ¼å¼

#### ğŸ“Š ç›‘æ§ä¸ä¼˜åŒ–
- **å®æ—¶æ€§èƒ½ç›‘æ§**: è¿½è¸ªå»¶è¿Ÿã€è´¨é‡ã€é”™è¯¯ç‡ç­‰å…³é”®æŒ‡æ ‡
- **è‡ªåŠ¨å¥åº·æ£€æŸ¥**: å®šæœŸæ£€æµ‹æœåŠ¡çŠ¶æ€ï¼ŒåŠæ—¶å‘ç°é—®é¢˜
- **LRUç¼“å­˜ä¼˜åŒ–**: æ™ºèƒ½ç¼“å­˜ç®¡ç†ï¼Œå¹³è¡¡å†…å­˜ä½¿ç”¨å’Œæ€§èƒ½
- **å®Œå–„é”™è¯¯å¤„ç†**: è‡ªåŠ¨é‡è¯•ã€ç†”æ–­ä¿æŠ¤ã€ä¼˜é›…é™çº§

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd services/realtime-processor
npm install
```

### 2. é…ç½®AzureæœåŠ¡

åœ¨ `.env` æ–‡ä»¶ä¸­æ·»åŠ Azureé…ç½®ï¼š

```env
# Azureè¯­éŸ³æœåŠ¡é…ç½®
AZURE_SPEECH_KEY=your_azure_speech_subscription_key
AZURE_SPEECH_REGION=eastasia
AZURE_SPEECH_ENDPOINT=https://eastasia.api.cognitive.microsoft.com/

# å¯é€‰é…ç½®
AZURE_SPEECH_LANGUAGE=zh-CN
AZURE_SPEECH_VOICE=zh-CN-XiaoxiaoNeural
```

### 3. åŸºç¡€ä½¿ç”¨ç¤ºä¾‹

```typescript
import { AzureSpeechService } from './src/azure';

// åˆå§‹åŒ–æœåŠ¡
const speechService = new AzureSpeechService({
  key: process.env.AZURE_SPEECH_KEY!,
  region: process.env.AZURE_SPEECH_REGION!,
  endpoint: process.env.AZURE_SPEECH_ENDPOINT!,
  language: 'zh-CN'
});

await speechService.initialize();

// å¤„ç†å®Œæ•´çš„è¯­éŸ³-åˆ°-è¯­éŸ³æµç¨‹
const result = await speechService.processAudio({
  id: 'request-001',
  callId: 'call-001',
  audioChunk: {
    id: 'chunk-001',
    callId: 'call-001',
    timestamp: Date.now(),
    audioData: audioBuffer, // éŸ³é¢‘æ•°æ®
    sequenceNumber: 1,
    sampleRate: 16000,
    channels: 1,
    format: 'wav'
  },
  userProfile: {
    userId: 'user-001',
    preferredVoice: 'zh-CN-XiaoxiaoNeural',
    personality: 'friendly',
    language: 'zh-CN'
  },
  options: {
    enableSTT: true,
    enableTTS: true,
    latencyOptimized: true,
    qualityMode: 'balanced'
  }
});

console.log('è¯†åˆ«ç»“æœ:', result.transcript?.text);
console.log('å›å¤éŸ³é¢‘å¤§å°:', result.response?.audioData.length);
console.log('æ€»å¤„ç†æ—¶é—´:', result.processingTime.total + 'ms');
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
services/realtime-processor/src/azure/
â”œâ”€â”€ AzureSpeechService.ts      # ä¸»è¦è¯­éŸ³æœåŠ¡æ§åˆ¶å™¨
â”œâ”€â”€ AzureSTTService.ts         # è¯­éŸ³è½¬æ–‡å­—æœåŠ¡
â”œâ”€â”€ AzureTTSService.ts         # æ–‡å­—è½¬è¯­éŸ³æœåŠ¡
â”œâ”€â”€ SpeechConfigManager.ts     # é…ç½®ç®¡ç†å™¨
â”œâ”€â”€ index.ts                   # æ¨¡å—å¯¼å‡º
â”œâ”€â”€ README.md                  # è¯¦ç»†APIæ–‡æ¡£
â””â”€â”€ AzureService.test.ts       # å•å…ƒæµ‹è¯•

src/examples/
â””â”€â”€ azureIntegrationExample.ts # é›†æˆä½¿ç”¨ç¤ºä¾‹

package.json                   # æ›´æ–°äº†Azureä¾èµ–
```

## ğŸ”§ ä¸»è¦ç»„ä»¶ä»‹ç»

### 1. AzureSpeechService (ä¸»æ§åˆ¶å™¨)

ç»Ÿä¸€çš„è¯­éŸ³å¤„ç†æ¥å£ï¼Œé›†æˆSTTå’ŒTTSæœåŠ¡ï¼š

```typescript
const speechService = new AzureSpeechService(azureConfig);

// å®Œæ•´è¯­éŸ³å¤„ç†æµç¨‹
const result = await speechService.processAudio(request);

// æµå¼å¤„ç†
const sessionId = await speechService.processAudioStream(request);

// æ€§èƒ½ç›‘æ§
const health = speechService.getHealthStatus();
const metrics = speechService.getPerformanceMetrics();
```

### 2. AzureSTTService (è¯­éŸ³è¯†åˆ«)

ä¸“é—¨çš„è¯­éŸ³è½¬æ–‡å­—æœåŠ¡ï¼š

```typescript
const sttService = new AzureSTTService(azureConfig);

// å¼€å§‹è¯†åˆ«ä¼šè¯
const sessionId = await sttService.startSession(config);

// å¤„ç†éŸ³é¢‘æµ
await sttService.processAudioStream(sessionId, audioChunk);

// ç›‘å¬è¯†åˆ«ç»“æœ
sttService.on('finalResult', (result) => {
  console.log('è¯†åˆ«æ–‡æœ¬:', result.text);
  console.log('ç½®ä¿¡åº¦:', result.confidence);
});
```

### 3. AzureTTSService (è¯­éŸ³åˆæˆ)

ä¸“é—¨çš„æ–‡å­—è½¬è¯­éŸ³æœåŠ¡ï¼š

```typescript
const ttsService = new AzureTTSService(azureConfig);

// å•æ¬¡åˆæˆ
const result = await ttsService.synthesize({
  id: 'tts-001',
  text: 'æ‚¨å¥½ï¼Œæˆ‘ç°åœ¨ä¸æ–¹ä¾¿æ¥å¬ç”µè¯ã€‚',
  voice: 'zh-CN-XiaoxiaoNeural',
  style: 'friendly'
});

// æµå¼åˆæˆ
const sessionId = await ttsService.synthesizeStream(request);

// é¢„è®¡ç®—å›å¤
const precomputedAudio = ttsService.getPrecomputedResponse('polite_decline');
```

### 4. SpeechConfigManager (é…ç½®ç®¡ç†)

çµæ´»çš„é…ç½®ç®¡ç†ç³»ç»Ÿï¼š

```typescript
const configManager = new SpeechConfigManager(azureConfig);

// è®¾ç½®è¯­éŸ³å‚æ•°
configManager.setSynthesisVoice('zh-CN-XiaoxiaoNeural');
configManager.setVoiceStyle('friendly', 1.2);
configManager.setProsody(1.1, 5, 0.9); // è¯­é€Ÿã€éŸ³è°ƒã€éŸ³é‡

// æ€§èƒ½ä¼˜åŒ–
configManager.setLatencyOptimization(true);
configManager.enableStreaming(true);

// æ™ºèƒ½æ¨è
const recommendedVoice = configManager.recommendVoice(userProfile);
```

## ğŸ¯ å»¶è¿Ÿä¼˜åŒ–ç­–ç•¥

### å½“å‰å®ç°çš„ä¼˜åŒ–æŠ€æœ¯

1. **é¢„è®¡ç®—ç¼“å­˜**
   ```typescript
   // å¸¸ç”¨å›å¤é¢„åˆæˆ
   const precomputedAudio = ttsService.getPrecomputedResponse('polite_decline');
   if (precomputedAudio) {
     return precomputedAudio; // ç›´æ¥è¿”å›ï¼Œå»¶è¿Ÿ < 50ms
   }
   ```

2. **æµå¼å¤„ç†**
   ```typescript
   // è¾¹å¬è¾¹å¤„ç†ï¼Œé™ä½æ•´ä½“å»¶è¿Ÿ
   const sessionId = await speechService.processAudioStream(request);
   ```

3. **æ™ºèƒ½ç¼“å­˜**
   ```typescript
   // LRUç¼“å­˜è‡ªåŠ¨ç®¡ç†
   const cacheStats = ttsService.getCacheStats();
   console.log('ç¼“å­˜å‘½ä¸­ç‡:', cacheStats.hitRate);
   ```

4. **æ ¼å¼ä¼˜åŒ–**
   ```typescript
   // ä½¿ç”¨OPUSæ ¼å¼å‡å°‘ä¼ è¾“æ—¶é—´
   configManager.setAudioFormat('opus', 16000);
   ```

### æ€§èƒ½ç›®æ ‡

| é˜¶æ®µ | ç›®æ ‡å»¶è¿Ÿ | ç­–ç•¥ |
|------|----------|------|
| MVPé˜¶æ®µ | < 1500ms | åŸºç¡€ç¼“å­˜ + å¹¶è¡Œå¤„ç† |
| ä¼˜åŒ–é˜¶æ®µ | < 1000ms | æµå¼å¤„ç† + é¢„æµ‹ç¼“å­˜ |
| ç”Ÿäº§é˜¶æ®µ | < 800ms | æ·±åº¦ä¼˜åŒ– + è¾¹ç¼˜è®¡ç®— |

## ğŸ“Š ç›‘æ§å’Œè¯Šæ–­

### å¥åº·çŠ¶æ€ç›‘æ§

```typescript
const health = speechService.getHealthStatus();

console.log('STTçŠ¶æ€:', health.stt.status);      // healthy/degraded/down
console.log('STTå»¶è¿Ÿ:', health.stt.latency);     // å¹³å‡å»¶è¿Ÿ(ms)
console.log('TTSç¼“å­˜å‘½ä¸­ç‡:', health.tts.cacheHitRate); // 0-1
console.log('æ•´ä½“çŠ¶æ€:', health.overall.status);  // ç»¼åˆå¥åº·çŠ¶æ€
```

### æ€§èƒ½æŒ‡æ ‡åˆ†æ

```typescript
const metrics = speechService.getPerformanceMetrics();
const avgLatency = metrics.reduce((sum, m) => sum + m.latency.totalPipeline, 0) / metrics.length;

console.log('å¹³å‡æ€»å»¶è¿Ÿ:', avgLatency + 'ms');
console.log('STTå¹³å‡å»¶è¿Ÿ:', metrics[0].latency.speechToText + 'ms');
console.log('TTSå¹³å‡å»¶è¿Ÿ:', metrics[0].latency.textToSpeech + 'ms');
```

### äº‹ä»¶ç›‘å¬

```typescript
// ç›‘å¬å…³é”®äº‹ä»¶
speechService.on('processingCompleted', (result) => {
  if (result.processingTime.total > 1500) {
    console.warn('å¤„ç†å»¶è¿Ÿè¿‡é«˜:', result.processingTime);
  }
});

speechService.on('error', (error) => {
  console.error('æœåŠ¡é”™è¯¯:', error);
  // å®ç°é”™è¯¯æ¢å¤é€»è¾‘
});

speechService.on('metricsUpdated', (health) => {
  if (health.overall.status === 'degraded') {
    console.warn('æœåŠ¡æ€§èƒ½ä¸‹é™');
    // è§¦å‘å‘Šè­¦æˆ–è‡ªåŠ¨æ¢å¤
  }
});
```

## ğŸ”§ é«˜çº§é…ç½®

### ç”¨æˆ·ç”»åƒé…ç½®

```typescript
interface UserProfile {
  userId: string;
  preferredVoice?: string;      // é¦–é€‰è¯­éŸ³
  personality?: string;         // 'friendly' | 'professional' | 'casual'
  speechStyle?: string;         // 'general' | 'assistant' | 'chat'
  language?: string;           // 'zh-CN' | 'en-US' | etc.
}

// æ ¹æ®ç”¨æˆ·ç”»åƒè‡ªåŠ¨é…ç½®
await speechService.configureVoice(userProfile);
```

### è´¨é‡æ¨¡å¼è®¾ç½®

```typescript
// ä¸åŒè´¨é‡æ¨¡å¼çš„æƒè¡¡
const qualityModes = {
  'fast': {
    latencyOptimized: true,
    compressionLevel: 3,
    sampleRate: 16000
  },
  'balanced': {
    latencyOptimized: true,
    compressionLevel: 6,
    sampleRate: 24000
  },
  'high': {
    latencyOptimized: false,
    compressionLevel: 9,
    sampleRate: 48000
  }
};
```

### ç¼“å­˜ç­–ç•¥é…ç½®

```typescript
// TTSç¼“å­˜é…ç½®
const cacheConfig = {
  maxSize: 100 * 1024 * 1024,    // 100MB
  maxAge: 24 * 60 * 60 * 1000,   // 24å°æ—¶
  cleanupInterval: 60 * 1000      // 1åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
};
```

## ğŸ§ª æµ‹è¯•

### è¿è¡Œå•å…ƒæµ‹è¯•

```bash
npm test -- --testPathPattern=azure
```

### è¿è¡Œé›†æˆç¤ºä¾‹

```bash
# è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
npm run dev -- src/examples/azureIntegrationExample.ts

# æˆ–è€…å•ç‹¬è¿è¡Œç‰¹å®šç¤ºä¾‹
npm run dev -- -e "import('./src/examples/azureIntegrationExample').then(m => m.basicSpeechProcessingExample())"
```

### æµ‹è¯•è¦†ç›–çš„åŠŸèƒ½

- âœ… é…ç½®ç®¡ç†å™¨çš„æ‰€æœ‰é…ç½®é€‰é¡¹
- âœ… STTæœåŠ¡çš„ä¼šè¯ç®¡ç†å’ŒéŸ³é¢‘å¤„ç†
- âœ… TTSæœåŠ¡çš„åˆæˆã€æµå¼è¾“å‡ºã€ç¼“å­˜
- âœ… ä¸»æ§åˆ¶å™¨çš„å®Œæ•´è¯­éŸ³å¤„ç†æµç¨‹
- âœ… é”™è¯¯å¤„ç†å’Œå¼‚å¸¸æ¢å¤
- âœ… æ€§èƒ½ç›‘æ§å’Œå¥åº·æ£€æŸ¥

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è§£å†³

1. **åˆå§‹åŒ–å¤±è´¥**
   ```bash
   é”™è¯¯: Azure Speech Service initialization failed
   è§£å†³: æ£€æŸ¥APIå¯†é’¥ã€åŒºåŸŸé…ç½®å’Œç½‘ç»œè¿æ¥
   ```

2. **è¯†åˆ«ç²¾åº¦ä½**
   ```bash
   é—®é¢˜: è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡ä¸é«˜
   è§£å†³: æ£€æŸ¥éŸ³é¢‘è´¨é‡ã€è°ƒæ•´é‡‡æ ·ç‡ã€é€‰æ‹©åˆé€‚è¯­è¨€æ¨¡å‹
   ```

3. **åˆæˆå»¶è¿Ÿé«˜**
   ```bash
   é—®é¢˜: TTSåˆæˆæ—¶é—´è¿‡é•¿
   è§£å†³: å¯ç”¨ç¼“å­˜ã€ä½¿ç”¨æµå¼åˆæˆã€ä¼˜åŒ–éŸ³é¢‘æ ¼å¼
   ```

4. **å†…å­˜ä½¿ç”¨è¿‡é«˜**
   ```bash
   é—®é¢˜: æœåŠ¡å†…å­˜å ç”¨ä¸æ–­å¢é•¿
   è§£å†³: è°ƒæ•´ç¼“å­˜å¤§å°ã€å®šæœŸæ¸…ç†ä¼šè¯ã€ä½¿ç”¨æµå¼å¤„ç†
   ```

### è°ƒè¯•æŠ€å·§

```typescript
// å¯ç”¨è¯¦ç»†æ—¥å¿—
process.env.LOG_LEVEL = 'debug';

// ç›‘å¬è¯¦ç»†äº‹ä»¶
speechService.on('audioProcessed', (data) => {
  console.log('éŸ³é¢‘å¤„ç†è¯¦æƒ…:', data);
});

speechService.on('cacheHit', (data) => {
  console.log('ç¼“å­˜å‘½ä¸­:', data);
});
```

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### å½“å‰æ€§èƒ½æŒ‡æ ‡ (æµ‹è¯•ç¯å¢ƒ)

| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | çŠ¶æ€ |
|------|--------|--------|------|
| STTå»¶è¿Ÿ | ~350ms | <200ms | ğŸŸ¡ ä¼˜åŒ–ä¸­ |
| TTSå»¶è¿Ÿ | ~280ms | <200ms | ğŸŸ¡ ä¼˜åŒ–ä¸­ |
| æ€»å¤„ç†å»¶è¿Ÿ | ~800ms | <500ms | ğŸŸ¡ ä¼˜åŒ–ä¸­ |
| ç¼“å­˜å‘½ä¸­ç‡ | 75% | >90% | ğŸŸ¢ è‰¯å¥½ |
| é”™è¯¯ç‡ | <1% | <0.5% | ğŸŸ¢ è‰¯å¥½ |

### ä¼˜åŒ–å»ºè®®

1. **å¯ç”¨æ‰€æœ‰ä¼˜åŒ–é€‰é¡¹**
   ```typescript
   speechService.optimizeForLatency(true);
   configManager.setLatencyOptimization(true);
   configManager.enableStreaming(true);
   ```

2. **ä½¿ç”¨åˆé€‚çš„éŸ³é¢‘æ ¼å¼**
   ```typescript
   configManager.setAudioFormat('opus', 16000);
   ```

3. **é¢„çƒ­ç¼“å­˜**
   ```typescript
   // åº”ç”¨å¯åŠ¨æ—¶é¢„ç”Ÿæˆå¸¸ç”¨å›å¤
   await ttsService.precomputeCommonResponses();
   ```

## ğŸ”® æœªæ¥è§„åˆ’

### çŸ­æœŸä¼˜åŒ– (1-2ä¸ªæœˆ)
- [ ] å®ç°çœŸå®çš„Azure SDKé›†æˆ (å½“å‰ä¸ºæ¨¡æ‹Ÿå®ç°)
- [ ] æ·»åŠ è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«åŠŸèƒ½
- [ ] ä¼˜åŒ–éŸ³é¢‘æ ¼å¼è½¬æ¢æ€§èƒ½
- [ ] å®ç°æ™ºèƒ½è¯­éŸ³ä¸­æ–­æ£€æµ‹

### ä¸­æœŸåŠŸèƒ½ (3-6ä¸ªæœˆ)
- [ ] æ”¯æŒè‡ªå®šä¹‰è¯­éŸ³è®­ç»ƒ
- [ ] å®ç°å£°çº¹è¯†åˆ«
- [ ] æ·»åŠ å¤šæ–¹é€šè¯æ”¯æŒ
- [ ] é›†æˆè¯­éŸ³å¢å¼ºæŠ€æœ¯

### é•¿æœŸæ„¿æ™¯ (6-12ä¸ªæœˆ)
- [ ] è¾¹ç¼˜è®¡ç®—éƒ¨ç½²
- [ ] å®æ—¶è¯­éŸ³ç¿»è¯‘
- [ ] AIé©±åŠ¨çš„ä¸ªæ€§åŒ–è¯­éŸ³
- [ ] è·¨å¹³å°SDKå‘å¸ƒ

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœæ‚¨åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼š

1. æŸ¥çœ‹è¯¦ç»†çš„APIæ–‡æ¡£: `src/azure/README.md`
2. è¿è¡Œå•å…ƒæµ‹è¯•æ£€æŸ¥ç¯å¢ƒ: `npm test`
3. æŸ¥çœ‹é›†æˆç¤ºä¾‹: `src/examples/azureIntegrationExample.ts`
4. æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—å’Œç›‘æ§æŒ‡æ ‡

## ğŸ“„ è®¸å¯è¯

æœ¬é›†æˆéµå¾ªé¡¹ç›®ä¸»è®¸å¯è¯ã€‚ä½¿ç”¨Azure Speech Serviceséœ€è¦æœ‰æ•ˆçš„Azureè®¢é˜…ã€‚

---

ğŸ‰ **æ­å–œï¼** Azureè¯­éŸ³æœåŠ¡ç°å·²å®Œå…¨é›†æˆåˆ°å®æ—¶å¤„ç†æœåŠ¡ä¸­ï¼Œä¸ºAIç”µè¯åº”ç­”ç³»ç»Ÿæä¾›äº†å¼ºå¤§çš„è¯­éŸ³å¤„ç†èƒ½åŠ›ï¼