"""Real-time learning and conversation optimization service."""

import asyncio
import json
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from uuid import UUID, uuid4
from dataclasses import dataclass
from collections import deque, defaultdict
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import structlog

from ..core.config import settings
from ..core.cache import conversation_cache
from ..models.conversation import ConversationContext, AIResponse, IntentCategory, EmotionalState
from ..models.learning import (
    LearningEvent, ModelPerformance, OptimizationResult, 
    LearningType, OutcomeType, OptimizationStrategy,
    ContinuousLearningState, ExperimentResult
)
from ..models.user import UserProfileData

logger = structlog.get_logger(__name__)


@dataclass
class ConversationOutcome:
    """Represents the outcome of a conversation for learning."""
    call_id: str
    user_id: UUID
    success_score: float
    duration_seconds: float
    turn_count: int
    termination_reason: str
    intent_category: IntentCategory
    emotional_progression: List[EmotionalState]
    strategies_used: List[str]
    response_times: List[float]
    cache_hit_rate: float


class RealTimeLearningService:
    """Service for real-time learning and conversation optimization."""
    
    def __init__(self):
        self.learning_enabled = True
        self.learning_buffer = deque(maxlen=1000)  # Store recent learning events
        self.optimization_history = deque(maxlen=100)
        
        # Learning models
        self.response_effectiveness_model = LogisticRegression()
        self.termination_timing_model = RandomForestClassifier()
        self.intent_confidence_model = LogisticRegression()
        
        # Learning state tracking
        self.user_learning_states: Dict[str, ContinuousLearningState] = {}
        
        # Performance tracking
        self.model_performances: Dict[str, ModelPerformance] = {}
        
        # A/B testing framework
        self.active_experiments: Dict[str, ExperimentResult] = {}
        
        # Feature extractors
        self.conversation_features = ConversationFeatureExtractor()
        
        # Optimization parameters
        self.learning_rate = 0.01
        self.min_samples_for_update = 50
        self.confidence_threshold = 0.8
        
        logger.info(\"Real-time learning service initialized\")\n    \n    async def record_learning_event(\n        self,\n        conversation_outcome: ConversationOutcome,\n        ai_responses: List[AIResponse],\n        emotional_analysis: List[Dict[str, Any]]\n    ) -> None:\n        \"\"\"Record a learning event from conversation outcome.\"\"\"\n        try:\n            # Create learning event\n            learning_event = LearningEvent(\n                conversation_id=UUID(conversation_outcome.call_id.replace('-', '')[:32].ljust(32, '0')),\n                user_id=conversation_outcome.user_id,\n                learning_type=LearningType.RESPONSE_EFFECTIVENESS,\n                event_data={\n                    \"conversation_outcome\": conversation_outcome.__dict__,\n                    \"ai_responses\": [resp.dict() for resp in ai_responses],\n                    \"emotional_analysis\": emotional_analysis\n                },\n                outcome=self._determine_outcome_type(conversation_outcome),\n                success_score=conversation_outcome.success_score,\n                intent_category=conversation_outcome.intent_category,\n                emotional_context=conversation_outcome.emotional_progression,\n                conversation_stage=self._infer_final_stage(conversation_outcome),\n                response_time_ms=np.mean(conversation_outcome.response_times),\n                confidence=self._calculate_learning_confidence(conversation_outcome)\n            )\n            \n            # Add to learning buffer\n            self.learning_buffer.append(learning_event)\n            \n            # Update user learning state\n            await self._update_user_learning_state(\n                str(conversation_outcome.user_id),\n                learning_event\n            )\n            \n            # Trigger learning if buffer is full enough\n            if len(self.learning_buffer) >= self.min_samples_for_update:\n                await self._trigger_incremental_learning()\n            \n            logger.info(\n                \"Learning event recorded\",\n                call_id=conversation_outcome.call_id,\n                outcome=learning_event.outcome.value,\n                success_score=conversation_outcome.success_score\n            )\n            \n        except Exception as e:\n            logger.error(\n                \"Failed to record learning event\",\n                call_id=conversation_outcome.call_id,\n                error=str(e)\n            )\n    \n    async def optimize_response_strategy(\n        self,\n        context: ConversationContext,\n        user_profile: UserProfileData,\n        current_strategies: List[str]\n    ) -> Dict[str, Any]:\n        \"\"\"Optimize response strategy based on learned patterns.\"\"\"\n        try:\n            # Extract features from current context\n            features = self.conversation_features.extract_context_features(\n                context, user_profile\n            )\n            \n            # Get user learning state\n            user_learning = self.user_learning_states.get(\n                str(context.user_id),\n                self._create_default_learning_state(context.user_id)\n            )\n            \n            # Predict optimal strategy\n            strategy_recommendations = await self._predict_optimal_strategies(\n                features, user_learning, current_strategies\n            )\n            \n            # Apply A/B testing if active\n            if self.active_experiments:\n                strategy_recommendations = await self._apply_experiment_variations(\n                    context.call_id,\n                    strategy_recommendations\n                )\n            \n            optimization_result = {\n                \"recommended_strategies\": strategy_recommendations[\"strategies\"],\n                \"confidence\": strategy_recommendations[\"confidence\"],\n                \"expected_improvement\": strategy_recommendations[\"expected_improvement\"],\n                \"learning_phase\": user_learning.learning_phase,\n                \"adaptation_applied\": True,\n                \"optimization_reason\": strategy_recommendations[\"reason\"]\n            }\n            \n            logger.info(\n                \"Response strategy optimized\",\n                call_id=context.call_id,\n                strategies=strategy_recommendations[\"strategies\"][:3],  # Top 3\n                confidence=strategy_recommendations[\"confidence\"]\n            )\n            \n            return optimization_result\n            \n        except Exception as e:\n            logger.error(\n                \"Failed to optimize response strategy\",\n                call_id=context.call_id,\n                error=str(e)\n            )\n            # Return default strategy\n            return {\n                \"recommended_strategies\": current_strategies,\n                \"confidence\": 0.5,\n                \"expected_improvement\": 0.0,\n                \"learning_phase\": \"stable\",\n                \"adaptation_applied\": False,\n                \"error\": str(e)\n            }\n    \n    async def predict_conversation_outcome(\n        self,\n        context: ConversationContext,\n        user_profile: UserProfileData\n    ) -> Dict[str, Any]:\n        \"\"\"Predict likely conversation outcome and optimal termination timing.\"\"\"\n        try:\n            # Extract features\n            features = self.conversation_features.extract_prediction_features(\n                context, user_profile\n            )\n            \n            # Predict success probability\n            success_prob = await self._predict_success_probability(features)\n            \n            # Predict optimal termination timing\n            termination_prediction = await self._predict_termination_timing(\n                features, context\n            )\n            \n            # Predict caller behavior\n            caller_behavior = await self._predict_caller_behavior(\n                features, context.conversation_history\n            )\n            \n            prediction = {\n                \"success_probability\": success_prob,\n                \"recommended_termination_turn\": termination_prediction[\"turn\"],\n                \"termination_confidence\": termination_prediction[\"confidence\"],\n                \"predicted_caller_persistence\": caller_behavior[\"persistence_score\"],\n                \"predicted_frustration_level\": caller_behavior[\"frustration_level\"],\n                \"optimal_strategy_sequence\": termination_prediction[\"strategy_sequence\"],\n                \"confidence_interval\": termination_prediction[\"confidence_interval\"]\n            }\n            \n            logger.info(\n                \"Conversation outcome predicted\",\n                call_id=context.call_id,\n                success_probability=success_prob,\n                recommended_termination=termination_prediction[\"turn\"]\n            )\n            \n            return prediction\n            \n        except Exception as e:\n            logger.error(\n                \"Failed to predict conversation outcome\",\n                call_id=context.call_id,\n                error=str(e)\n            )\n            # Return neutral prediction\n            return {\n                \"success_probability\": 0.5,\n                \"recommended_termination_turn\": context.turn_count + 3,\n                \"termination_confidence\": 0.3,\n                \"predicted_caller_persistence\": 0.5,\n                \"predicted_frustration_level\": 0.3,\n                \"optimal_strategy_sequence\": [\"polite_decline\", \"firm_rejection\"],\n                \"error\": str(e)\n            }\n    \n    async def start_ab_experiment(\n        self,\n        experiment_name: str,\n        hypothesis: str,\n        treatment_variation: Dict[str, Any],\n        control_group_size: int = 100,\n        treatment_group_size: int = 100\n    ) -> ExperimentResult:\n        \"\"\"Start a new A/B testing experiment.\"\"\"\n        try:\n            experiment = ExperimentResult(\n                experiment_name=experiment_name,\n                user_id=UUID('00000000-0000-0000-0000-000000000000'),  # System experiment\n                control_group_size=control_group_size,\n                treatment_group_size=treatment_group_size,\n                duration_days=14,\n                hypothesis=hypothesis,\n                expected_improvement=treatment_variation.get(\"expected_improvement\", 0.1),\n                control_success_rate=0.0,  # Will be updated as data comes in\n                treatment_success_rate=0.0,\n                improvement_observed=0.0,\n                statistical_power=0.8,\n                p_value=1.0,\n                effect_size=0.0,\n                control_avg_response_time=0.0,\n                treatment_avg_response_time=0.0,\n                control_user_satisfaction=0.0,\n                treatment_user_satisfaction=0.0,\n                statistically_significant=False,\n                practically_significant=False,\n                recommendation=\"continue\",\n                start_date=datetime.utcnow(),\n                end_date=datetime.utcnow() + timedelta(days=14),\n                analyzed_date=datetime.utcnow()\n            )\n            \n            # Store experiment configuration\n            experiment_config = {\n                \"experiment\": experiment,\n                \"treatment_variation\": treatment_variation,\n                \"control_assignments\": [],\n                \"treatment_assignments\": [],\n                \"results_data\": {\n                    \"control_outcomes\": [],\n                    \"treatment_outcomes\": []\n                }\n            }\n            \n            self.active_experiments[experiment_name] = experiment_config\n            \n            logger.info(\n                \"A/B experiment started\",\n                experiment_name=experiment_name,\n                hypothesis=hypothesis,\n                duration_days=14\n            )\n            \n            return experiment\n            \n        except Exception as e:\n            logger.error(\n                \"Failed to start A/B experiment\",\n                experiment_name=experiment_name,\n                error=str(e)\n            )\n            raise\n    \n    async def get_learning_insights(\n        self,\n        user_id: Optional[UUID] = None,\n        time_period_days: int = 7\n    ) -> Dict[str, Any]:\n        \"\"\"Get insights from the learning system.\"\"\"\n        try:\n            end_date = datetime.utcnow()\n            start_date = end_date - timedelta(days=time_period_days)\n            \n            # Filter learning events by time period and user\n            relevant_events = [\n                event for event in self.learning_buffer\n                if event.timestamp >= start_date and \n                   (user_id is None or event.user_id == user_id)\n            ]\n            \n            if not relevant_events:\n                return {\n                    \"insights\": [],\n                    \"patterns\": [],\n                    \"recommendations\": [\"Insufficient data for analysis\"],\n                    \"learning_effectiveness\": 0.0\n                }\n            \n            # Analyze patterns\n            success_patterns = await self._analyze_success_patterns(relevant_events)\n            failure_patterns = await self._analyze_failure_patterns(relevant_events)\n            \n            # Calculate learning effectiveness\n            learning_effectiveness = self._calculate_learning_effectiveness(\n                relevant_events\n            )\n            \n            # Generate insights\n            insights = {\n                \"analysis_period\": {\n                    \"start_date\": start_date.isoformat(),\n                    \"end_date\": end_date.isoformat(),\n                    \"days\": time_period_days\n                },\n                \"data_summary\": {\n                    \"total_events\": len(relevant_events),\n                    \"successful_conversations\": len([e for e in relevant_events if e.success_score > 0.7]),\n                    \"failed_conversations\": len([e for e in relevant_events if e.success_score < 0.3]),\n                    \"avg_success_score\": np.mean([e.success_score for e in relevant_events])\n                },\n                \"success_patterns\": success_patterns,\n                \"failure_patterns\": failure_patterns,\n                \"learning_effectiveness\": learning_effectiveness,\n                \"model_performances\": {\n                    name: perf.dict() for name, perf in self.model_performances.items()\n                },\n                \"active_experiments\": len(self.active_experiments),\n                \"recommendations\": await self._generate_learning_recommendations(\n                    success_patterns, failure_patterns\n                )\n            }\n            \n            logger.info(\n                \"Learning insights generated\",\n                time_period_days=time_period_days,\n                total_events=len(relevant_events),\n                learning_effectiveness=learning_effectiveness\n            )\n            \n            return insights\n            \n        except Exception as e:\n            logger.error(\n                \"Failed to get learning insights\",\n                user_id=str(user_id) if user_id else \"system\",\n                error=str(e)\n            )\n            return {\"error\": str(e)}\n    \n    # Private helper methods\n    \n    def _determine_outcome_type(self, outcome: ConversationOutcome) -> OutcomeType:\n        \"\"\"Determine the outcome type based on conversation metrics.\"\"\"\n        if outcome.success_score >= 0.8:\n            return OutcomeType.SUCCESS\n        elif outcome.success_score >= 0.5:\n            return OutcomeType.PARTIAL_SUCCESS\n        elif outcome.termination_reason == \"timeout\":\n            return OutcomeType.TIMEOUT\n        elif \"error\" in outcome.termination_reason.lower():\n            return OutcomeType.ERROR\n        elif outcome.success_score < 0.3:\n            return OutcomeType.FAILURE\n        else:\n            return OutcomeType.INCONCLUSIVE\n    \n    def _infer_final_stage(self, outcome: ConversationOutcome) -> str:\n        \"\"\"Infer the final conversation stage from outcome.\"\"\"\n        if \"terminated\" in outcome.termination_reason:\n            return \"call_end\"\n        elif outcome.turn_count >= 8:\n            return \"hang_up_warning\"\n        else:\n            return \"polite_decline\"\n    \n    def _calculate_learning_confidence(\n        self,\n        outcome: ConversationOutcome\n    ) -> float:\n        \"\"\"Calculate confidence in learning from this outcome.\"\"\"\n        # Higher confidence for clear outcomes\n        if outcome.success_score > 0.8 or outcome.success_score < 0.2:\n            return 0.9\n        elif outcome.turn_count >= 5:  # More data points\n            return 0.7\n        else:\n            return 0.5\n    \n    async def _update_user_learning_state(\n        self,\n        user_id: str,\n        learning_event: LearningEvent\n    ) -> None:\n        \"\"\"Update user-specific learning state.\"\"\"\n        if user_id not in self.user_learning_states:\n            self.user_learning_states[user_id] = self._create_default_learning_state(\n                UUID(user_id)\n            )\n        \n        state = self.user_learning_states[user_id]\n        state.conversations_since_update += 1\n        state.performance_history.append(learning_event.success_score)\n        \n        # Update current performance score\n        recent_scores = state.performance_history[-10:]  # Last 10 conversations\n        state.current_performance_score = sum(recent_scores) / len(recent_scores)\n        \n        # Check if model update is needed\n        if state.conversations_since_update >= state.model_update_frequency:\n            await self._update_user_model(user_id, state)\n    \n    def _create_default_learning_state(self, user_id: UUID) -> ContinuousLearningState:\n        \"\"\"Create default learning state for new user.\"\"\"\n        return ContinuousLearningState(\n            user_id=user_id,\n            learning_enabled=True,\n            learning_phase=\"exploration\",\n            active_model_version=\"v1.0\",\n            model_update_frequency=100,\n            conversations_since_update=0,\n            current_performance_score=0.5,\n            performance_history=[],\n            learning_rate=0.01,\n            exploration_rate=0.1,\n            confidence_threshold=0.8\n        )\n    \n    async def _trigger_incremental_learning(self) -> None:\n        \"\"\"Trigger incremental learning from accumulated events.\"\"\"\n        try:\n            # Get recent events for training\n            recent_events = list(self.learning_buffer)[-self.min_samples_for_update:]\n            \n            # Update response effectiveness model\n            await self._update_response_effectiveness_model(recent_events)\n            \n            # Update termination timing model\n            await self._update_termination_timing_model(recent_events)\n            \n            logger.info(\n                \"Incremental learning completed\",\n                events_processed=len(recent_events)\n            )\n            \n        except Exception as e:\n            logger.error(\"Incremental learning failed\", error=str(e))\n    \n    async def _predict_optimal_strategies(\n        self,\n        features: Dict[str, Any],\n        user_learning: ContinuousLearningState,\n        current_strategies: List[str]\n    ) -> Dict[str, Any]:\n        \"\"\"Predict optimal response strategies.\"\"\"\n        # Simple rule-based prediction (would be ML-based in production)\n        strategy_scores = {\n            \"polite_decline\": 0.7,\n            \"firm_rejection\": 0.6,\n            \"humor_deflection\": 0.5,\n            \"professional_response\": 0.8,\n            \"empathetic_response\": 0.6\n        }\n        \n        # Adjust scores based on context\n        if features.get(\"turn_count\", 0) > 5:\n            strategy_scores[\"firm_rejection\"] += 0.2\n            strategy_scores[\"polite_decline\"] -= 0.1\n        \n        if features.get(\"emotional_state\") == \"frustrated\":\n            strategy_scores[\"empathetic_response\"] += 0.3\n            strategy_scores[\"humor_deflection\"] -= 0.2\n        \n        # Sort strategies by score\n        sorted_strategies = sorted(\n            strategy_scores.items(),\n            key=lambda x: x[1],\n            reverse=True\n        )\n        \n        return {\n            \"strategies\": [s[0] for s in sorted_strategies[:3]],\n            \"confidence\": user_learning.confidence_threshold,\n            \"expected_improvement\": 0.1,\n            \"reason\": \"learned_pattern_optimization\"\n        }\n    \n    async def _predict_success_probability(self, features: Dict[str, Any]) -> float:\n        \"\"\"Predict conversation success probability.\"\"\"\n        # Simplified prediction based on features\n        base_prob = 0.7\n        \n        # Adjust based on conversation length\n        turn_count = features.get(\"turn_count\", 0)\n        if turn_count > 8:\n            base_prob -= 0.3\n        elif turn_count > 5:\n            base_prob -= 0.1\n        \n        # Adjust based on emotional state\n        emotional_state = features.get(\"emotional_state\", \"neutral\")\n        if emotional_state == \"frustrated\":\n            base_prob -= 0.2\n        elif emotional_state == \"polite\":\n            base_prob += 0.1\n        \n        return max(0.1, min(0.9, base_prob))\n    \n    async def _predict_termination_timing(\n        self,\n        features: Dict[str, Any],\n        context: ConversationContext\n    ) -> Dict[str, Any]:\n        \"\"\"Predict optimal termination timing.\"\"\"\n        current_turn = context.turn_count\n        \n        # Simple heuristic for termination timing\n        if features.get(\"caller_persistence\", 0.5) > 0.8:\n            recommended_turn = current_turn + 1  # Terminate soon\n            confidence = 0.8\n        elif features.get(\"emotional_state\") == \"frustrated\":\n            recommended_turn = current_turn + 2\n            confidence = 0.7\n        else:\n            recommended_turn = current_turn + 3\n            confidence = 0.6\n        \n        return {\n            \"turn\": recommended_turn,\n            \"confidence\": confidence,\n            \"strategy_sequence\": [\"polite_decline\", \"firm_rejection\", \"terminate\"],\n            \"confidence_interval\": (recommended_turn - 1, recommended_turn + 1)\n        }\n    \n    async def _predict_caller_behavior(\n        self,\n        features: Dict[str, Any],\n        conversation_history: List[Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Predict caller behavior patterns.\"\"\"\n        # Analyze conversation history for patterns\n        persistence_indicators = 0\n        frustration_indicators = 0\n        \n        for msg in conversation_history[-3:]:  # Last 3 messages\n            if hasattr(msg, 'text'):\n                text = msg.text.lower()\n                if any(word in text for word in [\"再考虑\", \"了解一下\", \"给个机会\"]):\n                    persistence_indicators += 1\n                if any(word in text for word in [\"为什么\", \"怎么不\", \"太过分\"]):\n                    frustration_indicators += 1\n        \n        persistence_score = min(1.0, persistence_indicators / 3.0)\n        frustration_level = min(1.0, frustration_indicators / 3.0)\n        \n        return {\n            \"persistence_score\": persistence_score,\n            \"frustration_level\": frustration_level,\n            \"predicted_next_action\": \"continue_calling\" if persistence_score > 0.6 else \"likely_to_stop\"\n        }\n    \n    def _calculate_learning_effectiveness(self, events: List[LearningEvent]) -> float:\n        \"\"\"Calculate overall learning effectiveness.\"\"\"\n        if not events:\n            return 0.0\n        \n        # Calculate improvement over time\n        early_scores = [e.success_score for e in events[:len(events)//2]]\n        recent_scores = [e.success_score for e in events[len(events)//2:]]\n        \n        if not early_scores or not recent_scores:\n            return 0.5\n        \n        early_avg = sum(early_scores) / len(early_scores)\n        recent_avg = sum(recent_scores) / len(recent_scores)\n        \n        improvement = (recent_avg - early_avg) / max(early_avg, 0.1)\n        return max(0.0, min(1.0, 0.5 + improvement))\n    \n    async def _analyze_success_patterns(self, events: List[LearningEvent]) -> List[Dict[str, Any]]:\n        \"\"\"Analyze patterns in successful conversations.\"\"\"\n        successful_events = [e for e in events if e.success_score > 0.7]\n        \n        if not successful_events:\n            return []\n        \n        patterns = [\n            {\n                \"pattern\": \"quick_resolution\",\n                \"frequency\": len([e for e in successful_events if e.response_time_ms < 200]) / len(successful_events),\n                \"description\": \"Fast response times correlate with success\"\n            },\n            {\n                \"pattern\": \"emotional_alignment\",\n                \"frequency\": 0.8,  # Placeholder\n                \"description\": \"Matching caller's emotional tone improves outcomes\"\n            }\n        ]\n        \n        return patterns\n    \n    async def _analyze_failure_patterns(self, events: List[LearningEvent]) -> List[Dict[str, Any]]:\n        \"\"\"Analyze patterns in failed conversations.\"\"\"\n        failed_events = [e for e in events if e.success_score < 0.3]\n        \n        if not failed_events:\n            return []\n        \n        patterns = [\n            {\n                \"pattern\": \"long_conversations\",\n                \"frequency\": 0.6,  # Placeholder\n                \"description\": \"Conversations exceeding 8 turns often fail\"\n            },\n            {\n                \"pattern\": \"escalating_frustration\",\n                \"frequency\": 0.7,  # Placeholder\n                \"description\": \"Increasing caller frustration leads to failure\"\n            }\n        ]\n        \n        return patterns\n    \n    async def _generate_learning_recommendations(\n        self,\n        success_patterns: List[Dict[str, Any]],\n        failure_patterns: List[Dict[str, Any]]\n    ) -> List[str]:\n        \"\"\"Generate actionable recommendations from learning analysis.\"\"\"\n        recommendations = []\n        \n        for pattern in success_patterns:\n            if pattern[\"frequency\"] > 0.7:\n                recommendations.append(\n                    f\"Reinforce {pattern['pattern']}: {pattern['description']}\"\n                )\n        \n        for pattern in failure_patterns:\n            if pattern[\"frequency\"] > 0.6:\n                recommendations.append(\n                    f\"Address {pattern['pattern']}: {pattern['description']}\"\n                )\n        \n        if not recommendations:\n            recommendations.append(\"Continue monitoring conversation patterns\")\n        \n        return recommendations\n    \n    async def get_performance_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get learning service performance metrics.\"\"\"\n        return {\n            \"learning_enabled\": self.learning_enabled,\n            \"total_learning_events\": len(self.learning_buffer),\n            \"active_experiments\": len(self.active_experiments),\n            \"user_learning_states\": len(self.user_learning_states),\n            \"model_performances\": len(self.model_performances),\n            \"learning_rate\": self.learning_rate,\n            \"confidence_threshold\": self.confidence_threshold,\n            \"service_status\": \"healthy\"\n        }\n\n\nclass ConversationFeatureExtractor:\n    \"\"\"Extracts features from conversation context for ML models.\"\"\"\n    \n    def extract_context_features(\n        self,\n        context: ConversationContext,\n        user_profile: UserProfileData\n    ) -> Dict[str, Any]:\n        \"\"\"Extract features from conversation context.\"\"\"\n        return {\n            \"turn_count\": context.turn_count,\n            \"conversation_duration\": (datetime.utcnow() - context.start_time).total_seconds(),\n            \"emotional_state\": context.emotional_state.value,\n            \"conversation_stage\": context.current_stage.value,\n            \"spam_category\": context.spam_category or \"unknown\",\n            \"user_personality\": user_profile.personality_type.value,\n            \"user_speech_style\": user_profile.speech_style.value,\n            \"history_length\": len(context.conversation_history),\n            \"caller_persistence\": self._calculate_caller_persistence(context),\n            \"emotional_volatility\": self._calculate_emotional_volatility(context)\n        }\n    \n    def extract_prediction_features(\n        self,\n        context: ConversationContext,\n        user_profile: UserProfileData\n    ) -> Dict[str, Any]:\n        \"\"\"Extract features for outcome prediction.\"\"\"\n        base_features = self.extract_context_features(context, user_profile)\n        \n        # Add prediction-specific features\n        base_features.update({\n            \"avg_response_time\": self._calculate_avg_response_time(context),\n            \"conversation_complexity\": self._calculate_conversation_complexity(context),\n            \"pattern_repetition\": self._detect_pattern_repetition(context)\n        })\n        \n        return base_features\n    \n    def _calculate_caller_persistence(self, context: ConversationContext) -> float:\n        \"\"\"Calculate caller persistence score.\"\"\"\n        if not context.conversation_history:\n            return 0.0\n        \n        user_messages = [msg for msg in context.conversation_history if msg.speaker == \"user\"]\n        if len(user_messages) < 2:\n            return 0.0\n        \n        # Simple heuristic based on message count and repetition\n        return min(1.0, len(user_messages) / 10.0)\n    \n    def _calculate_emotional_volatility(self, context: ConversationContext) -> float:\n        \"\"\"Calculate emotional volatility in conversation.\"\"\"\n        emotions = [msg.emotion for msg in context.conversation_history if msg.emotion]\n        if len(emotions) < 2:\n            return 0.0\n        \n        # Count emotional changes\n        changes = sum(1 for i in range(1, len(emotions)) if emotions[i] != emotions[i-1])\n        return changes / (len(emotions) - 1)\n    \n    def _calculate_avg_response_time(self, context: ConversationContext) -> float:\n        \"\"\"Calculate average AI response time.\"\"\"\n        ai_messages = [msg for msg in context.conversation_history if msg.speaker == \"ai\"]\n        response_times = [msg.processing_time_ms for msg in ai_messages if msg.processing_time_ms]\n        \n        return sum(response_times) / len(response_times) if response_times else 0.0\n    \n    def _calculate_conversation_complexity(self, context: ConversationContext) -> float:\n        \"\"\"Calculate conversation complexity score.\"\"\"\n        # Simple heuristic based on turn count and emotional changes\n        base_complexity = min(1.0, context.turn_count / 10.0)\n        emotional_complexity = self._calculate_emotional_volatility(context)\n        \n        return (base_complexity + emotional_complexity) / 2.0\n    \n    def _detect_pattern_repetition(self, context: ConversationContext) -> float:\n        \"\"\"Detect repetitive patterns in conversation.\"\"\"\n        user_messages = [msg.text for msg in context.conversation_history if msg.speaker == \"user\"]\n        \n        if len(user_messages) < 2:\n            return 0.0\n        \n        # Simple repetition detection\n        repetitions = 0\n        for i in range(1, len(user_messages)):\n            current_words = set(user_messages[i].lower().split())\n            previous_words = set(user_messages[i-1].lower().split())\n            \n            if len(current_words & previous_words) >= 3:  # 3+ common words\n                repetitions += 1\n        \n        return repetitions / max(len(user_messages) - 1, 1)\n\n\n# Global learning service instance\nlearning_optimizer = RealTimeLearningService()"