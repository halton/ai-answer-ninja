global:
  # SMTPé…ç½®
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@ai-answer-ninja.com'
  smtp_auth_username: 'alerts@ai-answer-ninja.com'
  smtp_auth_password: '${SMTP_PASSWORD}'
  smtp_require_tls: true

# å‘Šè­¦è·¯ç”±è§„åˆ™
route:
  group_by: ['alertname', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default-receiver'
  routes:
    # å…³é”®æœåŠ¡å‘Šè­¦
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      repeat_interval: 30m
      routes:
        # ç”Ÿäº§ç¯å¢ƒå…³é”®å‘Šè­¦ç«‹å³é€šçŸ¥
        - match:
            environment: production
          receiver: 'production-critical'
          group_wait: 0s
          repeat_interval: 15m

    # è­¦å‘Šçº§åˆ«å‘Šè­¦
    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_wait: 1m
      repeat_interval: 2h

    # ä¿¡æ¯çº§åˆ«å‘Šè­¦
    - match:
        severity: info
      receiver: 'info-alerts'
      group_wait: 5m
      repeat_interval: 24h

    # å®‰å…¨ç›¸å…³å‘Šè­¦
    - match_re:
        alertname: '.*[Ss]ecurity.*|.*[Aa]uth.*|.*[Aa]ttack.*'
      receiver: 'security-alerts'
      group_wait: 30s
      repeat_interval: 1h

    # æ•°æ®åº“ç›¸å…³å‘Šè­¦
    - match_re:
        alertname: '.*PostgreSQL.*|.*Redis.*|.*Database.*'
      receiver: 'database-alerts'
      group_wait: 1m
      repeat_interval: 1h

    # Kuberneteså‘Šè­¦
    - match_re:
        alertname: '.*Kubernetes.*|.*Kube.*'
      receiver: 'infrastructure-alerts'
      group_wait: 2m
      repeat_interval: 2h

# é€šçŸ¥æ¥æ”¶å™¨
receivers:
  # é»˜è®¤æ¥æ”¶å™¨
  - name: 'default-receiver'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts'
        title: 'AI Answer Ninja Alert'
        text: |
          {{ range .Alerts }}
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Severity:** {{ .Labels.severity }}
          **Service:** {{ .Labels.job }}
          **Environment:** {{ .Labels.environment }}
          {{ end }}
        send_resolved: true

  # å…³é”®å‘Šè­¦æ¥æ”¶å™¨
  - name: 'critical-alerts'
    # Slacké€šçŸ¥
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#critical-alerts'
        title: 'ğŸš¨ CRITICAL ALERT'
        text: |
          {{ range .Alerts }}
          ğŸš¨ **CRITICAL ALERT** ğŸš¨
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Service:** {{ .Labels.job }}
          **Instance:** {{ .Labels.instance }}
          **Environment:** {{ .Labels.environment }}
          **Started:** {{ .StartsAt }}
          {{ end }}
        send_resolved: true
        color: 'danger'
    
    # é‚®ä»¶é€šçŸ¥
    email_configs:
      - to: 'oncall@ai-answer-ninja.com'
        subject: 'ğŸš¨ Critical Alert: {{ .GroupLabels.alertname }}'
        html: |
          <h2>Critical Alert Triggered</h2>
          {{ range .Alerts }}
          <h3>{{ .Annotations.summary }}</h3>
          <p><strong>Description:</strong> {{ .Annotations.description }}</p>
          <p><strong>Service:</strong> {{ .Labels.job }}</p>
          <p><strong>Instance:</strong> {{ .Labels.instance }}</p>
          <p><strong>Environment:</strong> {{ .Labels.environment }}</p>
          <p><strong>Started:</strong> {{ .StartsAt }}</p>
          <p><strong>Alert Link:</strong> <a href="http://prometheus.ai-answer-ninja.com/alerts">View in Prometheus</a></p>
          {{ end }}
    
    # Teamsé€šçŸ¥
    msteams_configs:
      - webhook_url: '${MS_TEAMS_WEBHOOK_URL}'
        title: 'ğŸš¨ Critical Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Service:** {{ .Labels.job }}
          **Environment:** {{ .Labels.environment }}
          {{ end }}
        send_resolved: true

  # ç”Ÿäº§ç¯å¢ƒå…³é”®å‘Šè­¦
  - name: 'production-critical'
    # PagerDutyé›†æˆ
    pagerduty_configs:
      - routing_key: '${PAGERDUTY_ROUTING_KEY}'
        description: '{{ .GroupLabels.alertname }}: {{ .Annotations.summary }}'
        severity: 'critical'
        details:
          alert: '{{ .GroupLabels.alertname }}'
          description: '{{ .Annotations.description }}'
          environment: '{{ .Labels.environment }}'
          service: '{{ .Labels.job }}'
          instance: '{{ .Labels.instance }}'
    
    # Slackå…³é”®é€šçŸ¥
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#production-alerts'
        username: 'AlertManager'
        title: 'ğŸ”¥ PRODUCTION CRITICAL ğŸ”¥'
        text: |
          <!channel>
          {{ range .Alerts }}
          ğŸ”¥ **PRODUCTION CRITICAL** ğŸ”¥
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Service:** {{ .Labels.job }}
          **Instance:** {{ .Labels.instance }}
          **Started:** {{ .StartsAt }}
          **Runbook:** https://runbooks.ai-answer-ninja.com/{{ .Labels.alertname }}
          {{ end }}
        send_resolved: true
        color: 'danger'

  # è­¦å‘Šçº§åˆ«å‘Šè­¦
  - name: 'warning-alerts'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#warnings'
        title: 'âš ï¸ Warning Alert'
        text: |
          {{ range .Alerts }}
          âš ï¸ **Warning Alert**
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Service:** {{ .Labels.job }}
          **Environment:** {{ .Labels.environment }}
          {{ end }}
        send_resolved: true
        color: 'warning'

  # ä¿¡æ¯çº§åˆ«å‘Šè­¦
  - name: 'info-alerts'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#info-alerts'
        title: 'â„¹ï¸ Info Alert'
        text: |
          {{ range .Alerts }}
          â„¹ï¸ **Info Alert**
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Service:** {{ .Labels.job }}
          {{ end }}
        send_resolved: true

  # å®‰å…¨å‘Šè­¦
  - name: 'security-alerts'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#security-alerts'
        title: 'ğŸ›¡ï¸ Security Alert'
        text: |
          {{ range .Alerts }}
          ğŸ›¡ï¸ **Security Alert**
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Service:** {{ .Labels.job }}
          **Source:** {{ .Labels.source_ip }}
          **Environment:** {{ .Labels.environment }}
          {{ end }}
        send_resolved: true
        color: 'danger'
    
    email_configs:
      - to: 'security@ai-answer-ninja.com'
        subject: 'ğŸ›¡ï¸ Security Alert: {{ .GroupLabels.alertname }}'
        html: |
          <h2>Security Alert</h2>
          {{ range .Alerts }}
          <h3>{{ .Annotations.summary }}</h3>
          <p><strong>Description:</strong> {{ .Annotations.description }}</p>
          <p><strong>Service:</strong> {{ .Labels.job }}</p>
          <p><strong>Source IP:</strong> {{ .Labels.source_ip }}</p>
          <p><strong>Environment:</strong> {{ .Labels.environment }}</p>
          <p><strong>Started:</strong> {{ .StartsAt }}</p>
          {{ end }}

  # æ•°æ®åº“å‘Šè­¦
  - name: 'database-alerts'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#database-alerts'
        title: 'ğŸ’¾ Database Alert'
        text: |
          {{ range .Alerts }}
          ğŸ’¾ **Database Alert**
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Database:** {{ .Labels.datname }}{{ .Labels.db }}
          **Instance:** {{ .Labels.instance }}
          **Environment:** {{ .Labels.environment }}
          {{ end }}
        send_resolved: true
        color: 'warning'

  # åŸºç¡€è®¾æ–½å‘Šè­¦
  - name: 'infrastructure-alerts'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#infrastructure'
        title: 'ğŸ—ï¸ Infrastructure Alert'
        text: |
          {{ range .Alerts }}
          ğŸ—ï¸ **Infrastructure Alert**
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Node/Pod:** {{ .Labels.node }}{{ .Labels.pod }}
          **Namespace:** {{ .Labels.namespace }}
          **Environment:** {{ .Labels.environment }}
          {{ end }}
        send_resolved: true

# æŠ‘åˆ¶è§„åˆ™
inhibit_rules:
  # å½“æœåŠ¡å®•æœºæ—¶ï¼ŒæŠ‘åˆ¶é«˜å»¶è¿Ÿå‘Šè­¦
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: 'High.*Latency'
    equal: ['job', 'instance']

  # å½“èŠ‚ç‚¹å®•æœºæ—¶ï¼ŒæŠ‘åˆ¶æ‰€æœ‰ä¸è¯¥èŠ‚ç‚¹ç›¸å…³çš„å‘Šè­¦
  - source_match:
      alertname: 'KubernetesNodeNotReady'
    target_match_re:
      alertname: 'High.*Usage|.*Down'
    equal: ['instance']

# æ¨¡æ¿
templates:
  - '/etc/alertmanager/templates/*.tmpl'