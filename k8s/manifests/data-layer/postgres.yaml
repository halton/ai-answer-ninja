apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: ai-ninja
  labels:
    app: postgres
    tier: data
    version: v1
    app.kubernetes.io/name: postgres
    app.kubernetes.io/component: database
    app.kubernetes.io/part-of: ai-ninja
spec:
  serviceName: postgres-headless
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
        tier: data
        version: v1
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9187"
    spec:
      serviceAccountName: postgres-sa
      securityContext:
        fsGroup: 999
      initContainers:
      - name: postgres-init
        image: postgres:15-alpine
        command: 
        - sh
        - -c
        - |
          chown -R 999:999 /var/lib/postgresql/data
          chmod 700 /var/lib/postgresql/data
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
      containers:
      - name: postgres
        image: postgres:15-alpine
        ports:
        - name: postgres
          containerPort: 5432
          protocol: TCP
        env:
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: postgres-db
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: postgres-user
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: postgres-password
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        envFrom:
        - configMapRef:
            name: postgres-config
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 8Gi
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - $(POSTGRES_USER)
            - -d
            - $(POSTGRES_DB)
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 6
          successThreshold: 1
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - $(POSTGRES_USER)
            - -d
            - $(POSTGRES_DB)
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
          successThreshold: 1
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
        - name: postgres-config-volume
          mountPath: /etc/postgresql/postgresql.conf
          subPath: postgresql.conf
          readOnly: true
        - name: postgres-init-scripts
          mountPath: /docker-entrypoint-initdb.d
          readOnly: true
      - name: postgres-exporter
        image: prometheuscommunity/postgres-exporter:v0.11.1
        ports:
        - name: metrics
          containerPort: 9187
          protocol: TCP
        env:
        - name: DATA_SOURCE_NAME
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: postgres-exporter-url
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 256Mi
        livenessProbe:
          httpGet:
            path: /metrics
            port: metrics
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /metrics
            port: metrics
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: postgres-config-volume
        configMap:
          name: postgres-config
      - name: postgres-init-scripts
        configMap:
          name: postgres-init-scripts
          defaultMode: 0755
      nodeSelector:
        node-type: storage-optimized
      tolerations:
      - key: "node-type"
        operator: "Equal"
        value: "storage-optimized"
        effect: "NoSchedule"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - storage-optimized
                - general
  volumeClaimTemplates:
  - metadata:
      name: postgres-data
      labels:
        app: postgres
        tier: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: aws-gp3
      resources:
        requests:
          storage: 100Gi

---
apiVersion: v1
kind: Service
metadata:
  name: postgres-service
  namespace: ai-ninja
  labels:
    app: postgres
    tier: data
spec:
  type: ClusterIP
  selector:
    app: postgres
  ports:
  - name: postgres
    port: 5432
    targetPort: 5432
    protocol: TCP
  - name: metrics
    port: 9187
    targetPort: 9187
    protocol: TCP

---
apiVersion: v1
kind: Service
metadata:
  name: postgres-headless
  namespace: ai-ninja
  labels:
    app: postgres
    tier: data
spec:
  type: ClusterIP
  clusterIP: None
  selector:
    app: postgres
  ports:
  - name: postgres
    port: 5432
    targetPort: 5432
    protocol: TCP

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: postgres-sa
  namespace: ai-ninja
  labels:
    app: postgres
    tier: data

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: ai-ninja
  labels:
    app: postgres
    tier: data
data:
  # PostgreSQL Configuration
  POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
  POSTGRES_HOST_AUTH_METHOD: "scram-sha-256"
  POSTGRES_INITDB_WALDIR: "/var/lib/postgresql/data/pg_wal"
  
  # Performance tuning
  postgresql.conf: |
    # Connection settings
    max_connections = 200
    shared_buffers = 2GB
    effective_cache_size = 6GB
    maintenance_work_mem = 512MB
    checkpoint_completion_target = 0.9
    wal_buffers = 16MB
    default_statistics_target = 100
    random_page_cost = 1.1
    effective_io_concurrency = 200
    work_mem = 10MB
    min_wal_size = 1GB
    max_wal_size = 4GB
    
    # Logging
    log_destination = 'stderr'
    logging_collector = on
    log_directory = 'log'
    log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
    log_statement = 'ddl'
    log_min_duration_statement = 1000
    log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
    
    # Replication
    wal_level = replica
    max_wal_senders = 3
    wal_keep_size = 1GB
    
    # Monitoring
    shared_preload_libraries = 'pg_stat_statements'
    pg_stat_statements.max = 10000
    pg_stat_statements.track = all

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-init-scripts
  namespace: ai-ninja
  labels:
    app: postgres
    tier: data
data:
  01-create-databases.sql: |
    -- Create application databases
    CREATE DATABASE ai_ninja_main;
    CREATE DATABASE ai_ninja_analytics;
    CREATE DATABASE ai_ninja_cache;
    
    -- Create users with appropriate permissions
    CREATE USER app_user WITH ENCRYPTED PASSWORD 'app_password_change_me';
    CREATE USER analytics_user WITH ENCRYPTED PASSWORD 'analytics_password_change_me';
    CREATE USER readonly_user WITH ENCRYPTED PASSWORD 'readonly_password_change_me';
    
    -- Grant permissions
    GRANT ALL PRIVILEGES ON DATABASE ai_ninja_main TO app_user;
    GRANT ALL PRIVILEGES ON DATABASE ai_ninja_analytics TO analytics_user;
    GRANT CONNECT ON DATABASE ai_ninja_main TO readonly_user;
    GRANT CONNECT ON DATABASE ai_ninja_analytics TO readonly_user;
    
    -- Enable extensions
    \c ai_ninja_main;
    CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
    CREATE EXTENSION IF NOT EXISTS "pgcrypto";
    CREATE EXTENSION IF NOT EXISTS "pg_stat_statements";
    
    \c ai_ninja_analytics;
    CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
    CREATE EXTENSION IF NOT EXISTS "pgcrypto";
    CREATE EXTENSION IF NOT EXISTS "pg_stat_statements";
    
  02-create-partitions.sql: |
    \c ai_ninja_main;
    
    -- Create partitioned tables (matching our database schema)
    CREATE TABLE IF NOT EXISTS call_records (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        user_id UUID NOT NULL,
        caller_phone VARCHAR(20) NOT NULL,
        call_type VARCHAR(20) NOT NULL,
        call_status VARCHAR(20) NOT NULL,
        start_time TIMESTAMP NOT NULL,
        end_time TIMESTAMP,
        duration_seconds INTEGER,
        azure_call_id VARCHAR(100),
        audio_recording_url TEXT,
        processing_metadata JSONB,
        year_month INTEGER GENERATED ALWAYS AS (EXTRACT(YEAR FROM start_time) * 100 + EXTRACT(MONTH FROM start_time)) STORED,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    ) PARTITION BY RANGE (year_month);
    
    -- Create initial partitions for current and next months
    DO $$
    DECLARE
        current_year_month INTEGER := EXTRACT(YEAR FROM CURRENT_DATE) * 100 + EXTRACT(MONTH FROM CURRENT_DATE);
        next_year_month INTEGER;
    BEGIN
        -- Calculate next month
        IF EXTRACT(MONTH FROM CURRENT_DATE) = 12 THEN
            next_year_month := (EXTRACT(YEAR FROM CURRENT_DATE) + 1) * 100 + 1;
        ELSE
            next_year_month := EXTRACT(YEAR FROM CURRENT_DATE) * 100 + EXTRACT(MONTH FROM CURRENT_DATE) + 1;
        END IF;
        
        -- Create partitions
        EXECUTE format('CREATE TABLE IF NOT EXISTS call_records_%s PARTITION OF call_records FOR VALUES FROM (%s) TO (%s)', 
                       current_year_month, current_year_month, next_year_month);
        EXECUTE format('CREATE TABLE IF NOT EXISTS call_records_%s PARTITION OF call_records FOR VALUES FROM (%s) TO (%s)', 
                       next_year_month, next_year_month, next_year_month + 1);
    END $$;