#!/bin/bash\n# AI Answer Ninja - Database Maintenance Script\n# Automated maintenance tasks for optimal database performance\n\nset -euo pipefail\n\n# ===========================================\n# Configuration\n# ===========================================\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nPROJECT_ROOT=\"$(cd \"${SCRIPT_DIR}/../..\" && pwd)\"\n\n# Database configuration\nDB_HOST=\"${DB_HOST:-localhost}\"\nDB_PORT=\"${DB_PORT:-5432}\"\nDB_NAME=\"${DB_NAME:-ai_ninja}\"\nDB_USER=\"${DB_USER:-ai_ninja_app}\"\nDB_PASSWORD=\"${DB_PASSWORD:-}\"\nLOG_DIR=\"${PROJECT_ROOT}/logs/database\"\nPGPASSWORD=\"${DB_PASSWORD}\"\nexport PGPASSWORD\n\n# Maintenance configuration\nVACUUM_THRESHOLD=\"20\" # Vacuum when dead tuple percentage > 20%\nANALYZE_THRESHOLD=\"10\" # Analyze when 10% of data has changed\nREINDEX_THRESHOLD=\"30\" # Reindex when bloat > 30%\nPARTITION_RETENTION_MONTHS=\"12\" # Keep partitions for 12 months\n\n# ===========================================\n# Logging Functions\n# ===========================================\n\nsetup_logging() {\n    mkdir -p \"${LOG_DIR}\"\n    LOG_FILE=\"${LOG_DIR}/maintenance-$(date '+%Y%m%d_%H%M%S').log\"\n    exec 1> >(tee -a \"${LOG_FILE}\")\n    exec 2> >(tee -a \"${LOG_FILE}\" >&2)\n}\n\nlog_info() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $*\"\n}\n\nlog_warn() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] [WARN] $*\" >&2\n}\n\nlog_error() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] [ERROR] $*\" >&2\n}\n\nlog_success() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] [SUCCESS] $*\"\n}\n\n# ===========================================\n# Database Maintenance Functions\n# ===========================================\n\nrun_vacuum_analyze() {\n    log_info \"Running VACUUM and ANALYZE operations...\"\n    \n    # Get tables that need maintenance\n    local tables_needing_vacuum\n    tables_needing_vacuum=$(psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -t -c \"\n        SELECT schemaname||'.'||tablename \n        FROM pg_stat_user_tables \n        WHERE schemaname = 'public'\n        AND (\n            (n_dead_tup::float / GREATEST(n_live_tup, 1)::float) > (${VACUUM_THRESHOLD}::float / 100)\n            OR last_vacuum IS NULL \n            OR last_vacuum < CURRENT_TIMESTAMP - INTERVAL '7 days'\n        )\n        ORDER BY n_dead_tup DESC;\n    \")\n    \n    if [[ -z \"${tables_needing_vacuum}\" ]]; then\n        log_info \"No tables need vacuuming\"\n    else\n        while IFS= read -r table; do\n            table=$(echo \"${table}\" | xargs)  # Trim whitespace\n            if [[ -n \"${table}\" ]]; then\n                log_info \"Vacuuming table: ${table}\"\n                psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"VACUUM (VERBOSE, ANALYZE) ${table};\"\n            fi\n        done <<< \"${tables_needing_vacuum}\"\n    fi\n    \n    # Full database ANALYZE for statistics\n    log_info \"Running database-wide ANALYZE...\"\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"ANALYZE;\"\n    \n    log_success \"VACUUM and ANALYZE completed\"\n}\n\nrun_reindex() {\n    log_info \"Checking indexes for rebuilding...\"\n    \n    # Find bloated indexes\n    local bloated_indexes\n    bloated_indexes=$(psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -t -c \"\n        SELECT schemaname||'.'||indexname\n        FROM pg_stat_user_indexes\n        WHERE schemaname = 'public'\n        AND idx_tup_read > 0\n        AND (idx_tup_fetch::float / idx_tup_read::float) < 0.7\n        ORDER BY pg_relation_size(indexrelid) DESC;\n    \")\n    \n    if [[ -z \"${bloated_indexes}\" ]]; then\n        log_info \"No indexes need rebuilding\"\n    else\n        while IFS= read -r index; do\n            index=$(echo \"${index}\" | xargs)  # Trim whitespace\n            if [[ -n \"${index}\" ]]; then\n                log_info \"Reindexing: ${index}\"\n                psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"REINDEX INDEX CONCURRENTLY ${index};\"\n            fi\n        done <<< \"${bloated_indexes}\"\n    fi\n    \n    log_success \"Index maintenance completed\"\n}\n\nmanage_partitions() {\n    log_info \"Managing partition tables...\"\n    \n    # Create future partitions\n    log_info \"Creating future partitions...\"\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" << 'EOF'\nDO $$\nDECLARE\n    start_date date;\n    end_date date;\n    partition_name text;\n    table_name text;\nBEGIN\n    -- Create partitions for next 3 months for both call_records and conversations\n    FOR table_name IN SELECT unnest(ARRAY['call_records', 'conversations']) LOOP\n        FOR i IN 1..3 LOOP\n            start_date := date_trunc('month', CURRENT_DATE + (i || ' months')::interval);\n            end_date := start_date + interval '1 month';\n            partition_name := table_name || '_' || to_char(start_date, 'YYYY_MM');\n            \n            -- Check if partition already exists\n            IF NOT EXISTS (SELECT 1 FROM pg_tables WHERE tablename = partition_name) THEN\n                EXECUTE format('CREATE TABLE %I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',\n                             partition_name, table_name, start_date, end_date);\n                RAISE NOTICE 'Created partition: %', partition_name;\n            END IF;\n        END LOOP;\n    END LOOP;\nEND $$;\nEOF\n    \n    # Drop old partitions\n    log_info \"Dropping old partitions...\"\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" << EOF\nDO \\$\\$\nDECLARE\n    partition_record RECORD;\n    cutoff_date date;\nBEGIN\n    cutoff_date := CURRENT_DATE - interval '${PARTITION_RETENTION_MONTHS} months';\n    \n    FOR partition_record IN\n        SELECT schemaname, tablename\n        FROM pg_tables\n        WHERE schemaname = 'public'\n        AND (tablename LIKE 'call_records_%' OR tablename LIKE 'conversations_%')\n        AND substring(tablename from '[0-9]{4}_[0-9]{2}\\$') IS NOT NULL\n    LOOP\n        -- Extract date from partition name and check if it's older than cutoff\n        IF to_date(substring(partition_record.tablename from '[0-9]{4}_[0-9]{2}\\$'), 'YYYY_MM') < cutoff_date THEN\n            EXECUTE format('DROP TABLE IF EXISTS %I.%I CASCADE', \n                         partition_record.schemaname, partition_record.tablename);\n            RAISE NOTICE 'Dropped old partition: %', partition_record.tablename;\n        END IF;\n    END LOOP;\nEND \\$\\$;\nEOF\n    \n    log_success \"Partition management completed\"\n}\n\ncleanup_old_data() {\n    log_info \"Cleaning up old data...\"\n    \n    # Clean up old monitoring data\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" << 'EOF'\n-- Clean up old health check results (keep last 30 days)\nDELETE FROM monitoring.health_check_results \nWHERE checked_at < CURRENT_TIMESTAMP - INTERVAL '30 days';\n\n-- Clean up old alert history (keep last 90 days)\nDELETE FROM monitoring.alert_history \nWHERE triggered_at < CURRENT_TIMESTAMP - INTERVAL '90 days';\n\n-- Clean up old backup job records (keep last 180 days)\nDELETE FROM backup_system.backup_jobs \nWHERE created_at < CURRENT_TIMESTAMP - INTERVAL '180 days'\nAND status IN ('completed', 'failed');\n\n-- Clean up old backup verifications\nDELETE FROM backup_system.backup_verifications \nWHERE verified_at < CURRENT_TIMESTAMP - INTERVAL '180 days';\nEOF\n    \n    log_success \"Old data cleanup completed\"\n}\n\nupdate_statistics() {\n    log_info \"Updating table statistics...\"\n    \n    # Update extended statistics\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" << 'EOF'\n-- Refresh materialized views\nDO $$\nBEGIN\n    -- Refresh if exists\n    IF EXISTS (SELECT 1 FROM pg_matviews WHERE matviewname = 'mv_call_analytics_summary') THEN\n        REFRESH MATERIALIZED VIEW CONCURRENTLY mv_call_analytics_summary;\n    END IF;\n    \n    IF EXISTS (SELECT 1 FROM pg_matviews WHERE matviewname = 'mv_conversation_intelligence') THEN\n        REFRESH MATERIALIZED VIEW CONCURRENTLY mv_conversation_intelligence;\n    END IF;\n    \n    IF EXISTS (SELECT 1 FROM pg_matviews WHERE matviewname = 'mv_spam_trend_analysis') THEN\n        REFRESH MATERIALIZED VIEW CONCURRENTLY mv_spam_trend_analysis;\n    END IF;\n    \n    IF EXISTS (SELECT 1 FROM pg_matviews WHERE matviewname = 'mv_user_behavior_analysis') THEN\n        REFRESH MATERIALIZED VIEW CONCURRENTLY mv_user_behavior_analysis;\n    END IF;\nEXCEPTION\n    WHEN OTHERS THEN\n        RAISE NOTICE 'Some materialized views could not be refreshed: %', SQLERRM;\nEND $$;\nEOF\n    \n    log_success \"Statistics update completed\"\n}\n\n# ===========================================\n# Health and Performance Checks\n# ===========================================\n\ncheck_database_health() {\n    log_info \"Running database health checks...\"\n    \n    # Database size and growth\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"\n        SELECT \n            'Database Size' as metric,\n            pg_size_pretty(pg_database_size(current_database())) as value;\n    \"\n    \n    # Connection statistics\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"\n        SELECT \n            'Active Connections' as metric,\n            count(*) as value\n        FROM pg_stat_activity \n        WHERE state = 'active';\n    \"\n    \n    # Lock information\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"\n        SELECT \n            'Blocked Queries' as metric,\n            count(*) as value\n        FROM pg_locks \n        WHERE NOT granted;\n    \"\n    \n    # Cache hit ratio\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"\n        SELECT \n            'Cache Hit Ratio' as metric,\n            round((sum(heap_blks_hit) / nullif(sum(heap_blks_hit + heap_blks_read), 0) * 100)::numeric, 2) || '%' as value\n        FROM pg_statio_user_tables;\n    \"\n    \n    log_success \"Health check completed\"\n}\n\noptimize_performance() {\n    log_info \"Running performance optimization...\"\n    \n    # Update table statistics for better query planning\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"\n        -- Reset statistics\n        SELECT pg_stat_reset();\n        \n        -- Force statistics collection\n        ANALYZE;\n    \"\n    \n    # Check for missing indexes\n    log_info \"Checking for potential missing indexes...\"\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"\n        SELECT \n            schemaname,\n            tablename,\n            seq_scan,\n            seq_tup_read,\n            CASE \n                WHEN seq_scan > 0 \n                THEN seq_tup_read / seq_scan \n                ELSE 0 \n            END as avg_seq_read\n        FROM pg_stat_user_tables\n        WHERE seq_scan > 1000\n        AND seq_tup_read / seq_scan > 10000\n        ORDER BY seq_tup_read DESC\n        LIMIT 10;\n    \"\n    \n    log_success \"Performance optimization completed\"\n}\n\n# ===========================================\n# Backup Integration\n# ===========================================\n\nrun_maintenance_backup() {\n    log_info \"Creating maintenance backup...\"\n    \n    # Check if backup system is available\n    if psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"\n        SELECT 1 FROM information_schema.schemata WHERE schema_name = 'backup_system'\n    \" | grep -q \"1 row\"; then\n        \n        # Create backup using backup system\n        local backup_result\n        backup_result=$(psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -t -c \"\n            SELECT backup_system.create_backup('full', null, 6, 4);\n        \")\n        \n        if [[ -n \"${backup_result}\" ]]; then\n            log_success \"Maintenance backup created: ${backup_result}\"\n        else\n            log_error \"Failed to create maintenance backup\"\n        fi\n    else\n        log_warn \"Backup system not available, skipping maintenance backup\"\n    fi\n}\n\n# ===========================================\n# Monitoring and Alerting\n# ===========================================\n\nlog_maintenance_metrics() {\n    log_info \"Logging maintenance metrics...\"\n    \n    # Log maintenance completion\n    psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" << EOF\nDO \\$\\$\nBEGIN\n    -- Log to monitoring system if available\n    IF EXISTS (SELECT 1 FROM information_schema.schemata WHERE schema_name = 'monitoring') THEN\n        INSERT INTO monitoring.health_check_results (\n            check_name, check_type, status, message, details\n        ) VALUES (\n            'database_maintenance',\n            'maintenance',\n            'healthy',\n            'Scheduled maintenance completed successfully',\n            jsonb_build_object(\n                'maintenance_type', 'scheduled',\n                'completed_at', extract(epoch from now()),\n                'operations', jsonb_build_array(\n                    'vacuum_analyze',\n                    'reindex',\n                    'partition_management',\n                    'cleanup',\n                    'statistics_update'\n                )\n            )\n        );\n    END IF;\nEND \\$\\$;\nEOF\n    \n    log_success \"Maintenance metrics logged\"\n}\n\nsend_maintenance_report() {\n    local report_file=\"${LOG_DIR}/maintenance-report-$(date '+%Y%m%d_%H%M%S').txt\"\n    \n    {\n        echo \"AI Answer Ninja - Database Maintenance Report\"\n        echo \"Completed: $(date)\"\n        echo \"Database: ${DB_HOST}:${DB_PORT}/${DB_NAME}\"\n        echo \"===========================================\"\n        echo\n        \n        echo \"Database Statistics After Maintenance:\"\n        psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"\n            SELECT \n                schemaname,\n                tablename,\n                n_live_tup as live_rows,\n                n_dead_tup as dead_rows,\n                last_vacuum,\n                last_analyze\n            FROM pg_stat_user_tables\n            WHERE schemaname = 'public'\n            ORDER BY n_live_tup DESC;\n        \"\n        \n        echo\n        echo \"Index Usage Statistics:\"\n        psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"\n            SELECT \n                schemaname,\n                tablename,\n                indexname,\n                idx_tup_read,\n                idx_tup_fetch\n            FROM pg_stat_user_indexes\n            WHERE schemaname = 'public'\n            AND idx_tup_read > 0\n            ORDER BY idx_tup_read DESC\n            LIMIT 20;\n        \"\n        \n    } > \"${report_file}\"\n    \n    log_success \"Maintenance report saved to: ${report_file}\"\n}\n\n# ===========================================\n# Main Maintenance Function\n# ===========================================\n\nmain() {\n    local operation=\"${1:-full}\"\n    \n    setup_logging\n    \n    log_info \"Starting database maintenance for AI Answer Ninja\"\n    log_info \"Database: ${DB_HOST}:${DB_PORT}/${DB_NAME}\"\n    log_info \"Operation: ${operation}\"\n    \n    # Check database connection\n    if ! psql -h \"${DB_HOST}\" -p \"${DB_PORT}\" -U \"${DB_USER}\" -d \"${DB_NAME}\" -c \"SELECT 1\" &> /dev/null; then\n        log_error \"Cannot connect to database\"\n        exit 1\n    fi\n    \n    case \"${operation}\" in\n        \"full\")\n            log_info \"Running full maintenance...\"\n            check_database_health\n            run_maintenance_backup\n            run_vacuum_analyze\n            manage_partitions\n            cleanup_old_data\n            update_statistics\n            run_reindex\n            optimize_performance\n            log_maintenance_metrics\n            send_maintenance_report\n            ;;\n            \n        \"vacuum\")\n            log_info \"Running vacuum and analyze only...\"\n            run_vacuum_analyze\n            ;;\n            \n        \"reindex\")\n            log_info \"Running reindex only...\"\n            run_reindex\n            ;;\n            \n        \"partitions\")\n            log_info \"Managing partitions only...\"\n            manage_partitions\n            ;;\n            \n        \"cleanup\")\n            log_info \"Running cleanup only...\"\n            cleanup_old_data\n            ;;\n            \n        \"health\")\n            log_info \"Running health check only...\"\n            check_database_health\n            optimize_performance\n            ;;\n            \n        \"backup\")\n            log_info \"Creating maintenance backup only...\"\n            run_maintenance_backup\n            ;;\n            \n        \"help\")\n            cat << EOF\nAI Answer Ninja - Database Maintenance Script\n\nUsage: $0 <operation>\n\nOperations:\n  full       - Run full maintenance (default)\n  vacuum     - VACUUM and ANALYZE tables\n  reindex    - Rebuild indexes\n  partitions - Manage partition tables\n  cleanup    - Clean up old data\n  health     - Health check and optimization\n  backup     - Create maintenance backup\n  help       - Show this help message\n\nEnvironment Variables:\n  DB_HOST    - Database host (default: localhost)\n  DB_PORT    - Database port (default: 5432)\n  DB_NAME    - Database name (default: ai_ninja)\n  DB_USER    - Database user (default: ai_ninja_app)\n  DB_PASSWORD - Database password\n\nExamples:\n  $0 full                    # Full maintenance\n  $0 vacuum                  # Vacuum and analyze only\n  $0 health                  # Health check only\n\nScheduling:\n  # Add to crontab for regular maintenance\n  0 2 * * 0 /path/to/database-maintenance.sh full  # Weekly full maintenance\n  0 1 * * * /path/to/database-maintenance.sh vacuum # Daily vacuum\n\nEOF\n            ;;\n            \n        *)\n            log_error \"Unknown operation: ${operation}\"\n            echo \"Use '$0 help' for usage information\"\n            exit 1\n            ;;\n    esac\n    \n    log_success \"Database maintenance operation '${operation}' completed successfully\"\n}\n\n# Handle script interruption\ntrap 'log_error \"Maintenance interrupted by user\"; exit 130' INT TERM\n\n# Run main function\nmain \"$@\"\n"}