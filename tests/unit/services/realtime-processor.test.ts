/**\n * Unit Tests for Realtime Processor Service\n * \n * Tests WebSocket communication, audio processing, Azure Speech Services integration,\n * and real-time performance with comprehensive mocking.\n */\n\nimport { jest, describe, it, expect, beforeEach, afterEach } from '@jest/globals';\nimport WebSocket from 'ws';\nimport { EventEmitter } from 'events';\nimport { AzureServicesMockFactory } from '../../mocks/azure-services.mock';\n\n// Mock WebSocket and related modules\njest.mock('ws');\njest.mock('microsoft-cognitiveservices-speech-sdk');\n\ndescribe('Realtime Processor Service', () => {\n  let realtimeService: any;\n  let mockWebSocketServer: any;\n  let mockAzureSpeech: any;\n  let mockAzureOpenAI: any;\n  \n  beforeEach(async () => {\n    // Setup mocks\n    mockAzureSpeech = AzureServicesMockFactory.getSpeechService();\n    mockAzureOpenAI = AzureServicesMockFactory.getOpenAIService();\n    \n    // Mock WebSocket Server\n    mockWebSocketServer = {\n      on: jest.fn(),\n      clients: new Set(),\n      close: jest.fn()\n    };\n    \n    (WebSocket.Server as jest.MockedClass<typeof WebSocket.Server>).mockImplementation(() => mockWebSocketServer as any);\n    \n    // Reset all mocks\n    jest.clearAllMocks();\n    AzureServicesMockFactory.resetAll();\n    \n    // Import service after mocks are set up\n    const realtimeModule = await import('../../../services/realtime-processor/src/services/RealtimeService');\n    realtimeService = new realtimeModule.RealtimeService();\n  });\n  \n  afterEach(() => {\n    AzureServicesMockFactory.clearAll();\n  });\n  \n  describe('WebSocket Connection Management', () => {\n    it('should initialize WebSocket server successfully', () => {\n      expect(WebSocket.Server).toHaveBeenCalledWith({\n        port: expect.any(Number),\n        path: '/realtime'\n      });\n      \n      expect(mockWebSocketServer.on).toHaveBeenCalledWith('connection', expect.any(Function));\n    });\n    \n    it('should handle client connection', () => {\n      const mockClient = new EventEmitter() as any;\n      mockClient.send = jest.fn();\n      mockClient.readyState = WebSocket.OPEN;\n      \n      // Simulate connection\n      const connectionHandler = mockWebSocketServer.on.mock.calls\n        .find(call => call[0] === 'connection')[1];\n      \n      connectionHandler(mockClient);\n      \n      expect(mockClient.send).toHaveBeenCalledWith(JSON.stringify({\n        type: 'connection_established',\n        timestamp: expect.any(Number)\n      }));\n    });\n    \n    it('should handle client disconnection gracefully', async () => {\n      const mockClient = new EventEmitter() as any;\n      mockClient.send = jest.fn();\n      mockClient.close = jest.fn();\n      mockClient.readyState = WebSocket.OPEN;\n      \n      const connectionHandler = mockWebSocketServer.on.mock.calls\n        .find(call => call[0] === 'connection')[1];\n      \n      connectionHandler(mockClient);\n      \n      // Simulate disconnection\n      mockClient.emit('close');\n      \n      // Verify cleanup\n      await testUtils.waitFor(() => !mockWebSocketServer.clients.has(mockClient));\n    });\n    \n    it('should handle multiple concurrent connections', () => {\n      const clientCount = 10;\n      const mockClients = [];\n      \n      const connectionHandler = mockWebSocketServer.on.mock.calls\n        .find(call => call[0] === 'connection')[1];\n      \n      for (let i = 0; i < clientCount; i++) {\n        const mockClient = new EventEmitter() as any;\n        mockClient.send = jest.fn();\n        mockClient.readyState = WebSocket.OPEN;\n        mockClient.id = `client-${i}`;\n        \n        mockClients.push(mockClient);\n        connectionHandler(mockClient);\n      }\n      \n      expect(mockWebSocketServer.clients.size).toBe(clientCount);\n    });\n  });\n  \n  describe('Audio Processing Pipeline', () => {\n    let mockClient: any;\n    \n    beforeEach(() => {\n      mockClient = new EventEmitter() as any;\n      mockClient.send = jest.fn();\n      mockClient.readyState = WebSocket.OPEN;\n      \n      const connectionHandler = mockWebSocketServer.on.mock.calls\n        .find(call => call[0] === 'connection')[1];\n      connectionHandler(mockClient);\n    });\n    \n    it('should process audio chunks in real-time', async () => {\n      const audioChunk = Buffer.from('mock-audio-data');\n      \n      mockAzureSpeech.recognizeSpeech = jest.fn().mockResolvedValue({\n        text: 'Hello, I am calling about insurance',\n        intent: 'insurance_sales',\n        confidence: 0.92\n      });\n      \n      // Simulate audio chunk message\n      mockClient.emit('message', JSON.stringify({\n        type: 'audio_chunk',\n        data: audioChunk.toString('base64'),\n        timestamp: Date.now()\n      }));\n      \n      // Wait for processing\n      await testUtils.waitFor(() => mockAzureSpeech.recognizeSpeech.mock.calls.length > 0);\n      \n      expect(mockAzureSpeech.recognizeSpeech).toHaveBeenCalledWith(\n        expect.any(Buffer),\n        expect.objectContaining({\n          language: 'en-US',\n          continuous: true\n        })\n      );\n    });\n    \n    it('should handle voice activity detection', async () => {\n      const silentChunk = Buffer.alloc(1024); // Silent audio\n      const activeChunk = Buffer.alloc(1024, 128); // Active audio\n      \n      // Send silent chunk\n      mockClient.emit('message', JSON.stringify({\n        type: 'audio_chunk',\n        data: silentChunk.toString('base64'),\n        timestamp: Date.now()\n      }));\n      \n      // Should not trigger speech recognition\n      await new Promise(resolve => setTimeout(resolve, 100));\n      expect(mockAzureSpeech.recognizeSpeech).not.toHaveBeenCalled();\n      \n      // Send active chunk\n      mockClient.emit('message', JSON.stringify({\n        type: 'audio_chunk',\n        data: activeChunk.toString('base64'),\n        timestamp: Date.now()\n      }));\n      \n      // Should trigger speech recognition\n      await testUtils.waitFor(() => mockAzureSpeech.recognizeSpeech.mock.calls.length > 0);\n    });\n    \n    it('should maintain audio quality metrics', async () => {\n      const audioChunk = Buffer.from('high-quality-audio-data');\n      \n      mockClient.emit('message', JSON.stringify({\n        type: 'audio_chunk',\n        data: audioChunk.toString('base64'),\n        timestamp: Date.now(),\n        sampleRate: 16000,\n        channels: 1\n      }));\n      \n      await testUtils.waitFor(() => mockClient.send.mock.calls.length > 0);\n      \n      const qualityResponse = mockClient.send.mock.calls\n        .find((call: any) => {\n          try {\n            const message = JSON.parse(call[0]);\n            return message.type === 'audio_quality';\n          } catch {\n            return false;\n          }\n        });\n      \n      expect(qualityResponse).toBeTruthy();\n      \n      const qualityData = JSON.parse(qualityResponse[0]);\n      expect(qualityData).toHaveAudioQuality(0.8);\n    });\n  });\n  \n  describe('Speech Recognition Integration', () => {\n    let mockClient: any;\n    \n    beforeEach(() => {\n      mockClient = new EventEmitter() as any;\n      mockClient.send = jest.fn();\n      mockClient.readyState = WebSocket.OPEN;\n      \n      const connectionHandler = mockWebSocketServer.on.mock.calls\n        .find(call => call[0] === 'connection')[1];\n      connectionHandler(mockClient);\n    });\n    \n    it('should perform continuous speech recognition', async () => {\n      mockAzureSpeech.startContinuousRecognition = jest.fn().mockResolvedValue({\n        sessionId: 'session-123',\n        recognizer: new EventEmitter()\n      });\n      \n      mockClient.emit('message', JSON.stringify({\n        type: 'start_recognition',\n        language: 'en-US',\n        continuous: true\n      }));\n      \n      await testUtils.waitFor(() => mockAzureSpeech.startContinuousRecognition.mock.calls.length > 0);\n      \n      expect(mockAzureSpeech.startContinuousRecognition).toHaveBeenCalledWith({\n        language: 'en-US',\n        continuous: true\n      });\n    });\n    \n    it('should handle partial recognition results', async () => {\n      const mockRecognizer = new EventEmitter();\n      \n      mockAzureSpeech.startContinuousRecognition = jest.fn().mockResolvedValue({\n        sessionId: 'session-123',\n        recognizer: mockRecognizer\n      });\n      \n      mockClient.emit('message', JSON.stringify({\n        type: 'start_recognition'\n      }));\n      \n      // Simulate partial recognition\n      mockRecognizer.emit('recognizing', {\n        text: 'Hello, I am calling about...',\n        confidence: 0.7\n      });\n      \n      await testUtils.waitFor(() => mockClient.send.mock.calls.length > 0);\n      \n      const partialResult = mockClient.send.mock.calls\n        .find((call: any) => {\n          try {\n            const message = JSON.parse(call[0]);\n            return message.type === 'partial_recognition';\n          } catch {\n            return false;\n          }\n        });\n      \n      expect(partialResult).toBeTruthy();\n      \n      const partialData = JSON.parse(partialResult[0]);\n      expect(partialData.text).toBe('Hello, I am calling about...');\n      expect(partialData.confidence).toBe(0.7);\n    });\n    \n    it('should handle final recognition results', async () => {\n      const mockRecognizer = new EventEmitter();\n      \n      mockAzureSpeech.startContinuousRecognition = jest.fn().mockResolvedValue({\n        sessionId: 'session-123',\n        recognizer: mockRecognizer\n      });\n      \n      mockClient.emit('message', JSON.stringify({\n        type: 'start_recognition'\n      }));\n      \n      // Simulate final recognition\n      mockRecognizer.emit('recognized', {\n        text: 'Hello, I am calling about your insurance policy.',\n        confidence: 0.92,\n        intent: 'insurance_sales',\n        duration: 2.5\n      });\n      \n      await testUtils.waitFor(() => {\n        return mockClient.send.mock.calls.some((call: any) => {\n          try {\n            const message = JSON.parse(call[0]);\n            return message.type === 'final_recognition';\n          } catch {\n            return false;\n          }\n        });\n      });\n      \n      const finalResult = mockClient.send.mock.calls\n        .find((call: any) => {\n          try {\n            const message = JSON.parse(call[0]);\n            return message.type === 'final_recognition';\n          } catch {\n            return false;\n          }\n        });\n      \n      const finalData = JSON.parse(finalResult[0]);\n      expect(finalData).toRecognizeIntentWithConfidence('insurance_sales', 0.9);\n    });\n  });\n  \n  describe('AI Response Generation', () => {\n    let mockClient: any;\n    \n    beforeEach(() => {\n      mockClient = new EventEmitter() as any;\n      mockClient.send = jest.fn();\n      mockClient.readyState = WebSocket.OPEN;\n      \n      const connectionHandler = mockWebSocketServer.on.mock.calls\n        .find(call => call[0] === 'connection')[1];\n      connectionHandler(mockClient);\n    });\n    \n    it('should generate AI response for recognized speech', async () => {\n      mockAzureOpenAI.generatePersonalizedResponse = jest.fn().mockResolvedValue({\n        text: 'Thank you for calling, but I\\'m not interested in insurance at this time.',\n        confidence: 0.88,\n        shouldTerminate: false\n      });\n      \n      mockClient.emit('message', JSON.stringify({\n        type: 'generate_response',\n        recognizedText: 'Hello, I am calling about your insurance policy.',\n        intent: 'insurance_sales',\n        userProfile: { personality: 'polite' }\n      }));\n      \n      await testUtils.waitFor(() => mockAzureOpenAI.generatePersonalizedResponse.mock.calls.length > 0);\n      \n      expect(mockAzureOpenAI.generatePersonalizedResponse).toHaveBeenCalledWith({\n        recognizedText: 'Hello, I am calling about your insurance policy.',\n        intent: 'insurance_sales',\n        userProfile: { personality: 'polite' }\n      });\n    });\n    \n    it('should generate text-to-speech for AI response', async () => {\n      mockAzureSpeech.synthesizeSpeech = jest.fn().mockResolvedValue(\n        Buffer.from('synthesized-audio')\n      );\n      \n      mockClient.emit('message', JSON.stringify({\n        type: 'synthesize_speech',\n        text: 'Thank you for calling, but I\\'m not interested.',\n        voiceProfile: 'custom-voice-123'\n      }));\n      \n      await testUtils.waitFor(() => mockAzureSpeech.synthesizeSpeech.mock.calls.length > 0);\n      \n      expect(mockAzureSpeech.synthesizeSpeech).toHaveBeenCalledWith(\n        'Thank you for calling, but I\\'m not interested.',\n        {\n          voiceProfile: 'custom-voice-123',\n          format: 'wav',\n          sampleRate: 16000\n        }\n      );\n      \n      // Should send synthesized audio back to client\n      await testUtils.waitFor(() => {\n        return mockClient.send.mock.calls.some((call: any) => {\n          try {\n            const message = JSON.parse(call[0]);\n            return message.type === 'synthesized_audio';\n          } catch {\n            return false;\n          }\n        });\n      });\n    });\n  });\n  \n  describe('Performance and Latency Tests', () => {\n    let mockClient: any;\n    \n    beforeEach(() => {\n      mockClient = new EventEmitter() as any;\n      mockClient.send = jest.fn();\n      mockClient.readyState = WebSocket.OPEN;\n      \n      const connectionHandler = mockWebSocketServer.on.mock.calls\n        .find(call => call[0] === 'connection')[1];\n      connectionHandler(mockClient);\n    });\n    \n    it('should process audio within latency requirements', async () => {\n      mockAzureSpeech.recognizeSpeech = jest.fn().mockResolvedValue({\n        text: 'Test recognition',\n        confidence: 0.9\n      });\n      \n      const audioProcessing = new Promise((resolve) => {\n        mockClient.send = jest.fn((data) => {\n          const message = JSON.parse(data);\n          if (message.type === 'recognition_result') {\n            resolve(message);\n          }\n        });\n      });\n      \n      mockClient.emit('message', JSON.stringify({\n        type: 'audio_chunk',\n        data: Buffer.from('audio-data').toString('base64'),\n        timestamp: Date.now()\n      }));\n      \n      await expect(audioProcessing).toCompleteWithinMs(500);\n    });\n    \n    it('should handle high-frequency audio chunks', async () => {\n      const chunkCount = 50;\n      const chunkInterval = 20; // 50 FPS\n      \n      mockAzureSpeech.recognizeSpeech = jest.fn().mockResolvedValue({\n        text: 'Streaming audio',\n        confidence: 0.85\n      });\n      \n      const promises = [];\n      \n      for (let i = 0; i < chunkCount; i++) {\n        const promise = new Promise((resolve) => {\n          setTimeout(() => {\n            mockClient.emit('message', JSON.stringify({\n              type: 'audio_chunk',\n              data: Buffer.from(`chunk-${i}`).toString('base64'),\n              timestamp: Date.now()\n            }));\n            resolve(i);\n          }, i * chunkInterval);\n        });\n        \n        promises.push(promise);\n      }\n      \n      await Promise.all(promises);\n      \n      // Wait for processing to complete\n      await new Promise(resolve => setTimeout(resolve, 1000));\n      \n      // Should handle all chunks without dropping\n      expect(mockClient.send).toHaveBeenCalledTimes(\n        expect.any(Number)\n      );\n    });\n    \n    it('should maintain performance under load', async () => {\n      const clientCount = 5;\n      const messageCount = 20;\n      const mockClients = [];\n      \n      const connectionHandler = mockWebSocketServer.on.mock.calls\n        .find(call => call[0] === 'connection')[1];\n      \n      // Setup multiple clients\n      for (let i = 0; i < clientCount; i++) {\n        const client = new EventEmitter() as any;\n        client.send = jest.fn();\n        client.readyState = WebSocket.OPEN;\n        client.id = `load-test-client-${i}`;\n        \n        mockClients.push(client);\n        connectionHandler(client);\n      }\n      \n      mockAzureSpeech.recognizeSpeech = jest.fn().mockResolvedValue({\n        text: 'Load test message',\n        confidence: 0.9\n      });\n      \n      const startTime = performance.now();\n      \n      // Send messages from all clients\n      const allPromises = [];\n      \n      for (const client of mockClients) {\n        for (let j = 0; j < messageCount; j++) {\n          const promise = new Promise((resolve) => {\n            setTimeout(() => {\n              client.emit('message', JSON.stringify({\n                type: 'audio_chunk',\n                data: Buffer.from(`load-test-${client.id}-${j}`).toString('base64'),\n                timestamp: Date.now()\n              }));\n              resolve(j);\n            }, Math.random() * 100);\n          });\n          \n          allPromises.push(promise);\n        }\n      }\n      \n      await Promise.all(allPromises);\n      \n      const processingTime = performance.now() - startTime;\n      \n      console.log(`Processed ${clientCount * messageCount} messages in ${processingTime.toFixed(2)}ms`);\n      \n      // Should maintain reasonable performance\n      expect(processingTime).toBeLessThan(5000); // 5 seconds for load test\n    });\n  });\n  \n  describe('Error Handling and Recovery', () => {\n    let mockClient: any;\n    \n    beforeEach(() => {\n      mockClient = new EventEmitter() as any;\n      mockClient.send = jest.fn();\n      mockClient.readyState = WebSocket.OPEN;\n      \n      const connectionHandler = mockWebSocketServer.on.mock.calls\n        .find(call => call[0] === 'connection')[1];\n      connectionHandler(mockClient);\n    });\n    \n    it('should handle Azure service failures gracefully', async () => {\n      mockAzureSpeech.recognizeSpeech = jest.fn().mockRejectedValue(\n        new Error('Azure Speech service unavailable')\n      );\n      \n      mockClient.emit('message', JSON.stringify({\n        type: 'audio_chunk',\n        data: Buffer.from('audio-data').toString('base64'),\n        timestamp: Date.now()\n      }));\n      \n      await testUtils.waitFor(() => {\n        return mockClient.send.mock.calls.some((call: any) => {\n          try {\n            const message = JSON.parse(call[0]);\n            return message.type === 'error';\n          } catch {\n            return false;\n          }\n        });\n      });\n      \n      const errorMessage = mockClient.send.mock.calls\n        .find((call: any) => {\n          try {\n            const message = JSON.parse(call[0]);\n            return message.type === 'error';\n          } catch {\n            return false;\n          }\n        });\n      \n      const errorData = JSON.parse(errorMessage[0]);\n      expect(errorData.error).toContain('Speech recognition failed');\n    });\n    \n    it('should handle malformed messages', async () => {\n      mockClient.emit('message', 'invalid-json-message');\n      \n      await testUtils.waitFor(() => {\n        return mockClient.send.mock.calls.some((call: any) => {\n          try {\n            const message = JSON.parse(call[0]);\n            return message.type === 'error' && message.error.includes('Invalid message format');\n          } catch {\n            return false;\n          }\n        });\n      });\n    });\n    \n    it('should implement connection recovery', async () => {\n      // Simulate connection drop\n      mockClient.readyState = WebSocket.CLOSED;\n      mockClient.emit('close');\n      \n      // Simulate reconnection\n      const newClient = new EventEmitter() as any;\n      newClient.send = jest.fn();\n      newClient.readyState = WebSocket.OPEN;\n      \n      const connectionHandler = mockWebSocketServer.on.mock.calls\n        .find(call => call[0] === 'connection')[1];\n      \n      connectionHandler(newClient);\n      \n      expect(newClient.send).toHaveBeenCalledWith(JSON.stringify({\n        type: 'connection_established',\n        timestamp: expect.any(Number)\n      }));\n    });\n  });\n});\n\n// Integration performance benchmarks\ndescribe('Realtime Processor Performance Benchmarks', () => {\n  it('should meet end-to-end latency requirements', async () => {\n    const mockAzureSpeech = AzureServicesMockFactory.getSpeechService();\n    const mockAzureOpenAI = AzureServicesMockFactory.getOpenAIService();\n    \n    mockAzureSpeech.recognizeSpeech = jest.fn().mockResolvedValue({\n      text: 'Performance test message',\n      intent: 'test',\n      confidence: 0.9\n    });\n    \n    mockAzureOpenAI.generatePersonalizedResponse = jest.fn().mockResolvedValue({\n      text: 'Performance test response',\n      confidence: 0.88\n    });\n    \n    mockAzureSpeech.synthesizeSpeech = jest.fn().mockResolvedValue(\n      Buffer.from('performance-test-audio')\n    );\n    \n    const realtimeModule = await import('../../../services/realtime-processor/src/services/RealtimeService');\n    const service = new realtimeModule.RealtimeService();\n    \n    const startTime = performance.now();\n    \n    // Simulate full pipeline: audio → STT → AI → TTS\n    const audioBuffer = Buffer.from('test-audio-data');\n    \n    await service.processAudioChunk(audioBuffer, {\n      sessionId: 'perf-test',\n      userProfile: { personality: 'polite' }\n    });\n    \n    const endToEndLatency = performance.now() - startTime;\n    \n    console.log(`End-to-end latency: ${endToEndLatency.toFixed(2)}ms`);\n    \n    // Should meet the target latency of < 800ms\n    expect(endToEndLatency).toBeLessThan(800);\n  });\n});\n"